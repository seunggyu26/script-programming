{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. 파일 s.txt 내의 다음 내용과 함께 아래 문제의 코드를 제시하시오.\n",
    "####pig ham<br />cat dog<br />ham bird<br />dog pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####1) 파일 s.txt을 읽어서 각 라인에 있는 첫 번째 단어(문자열) 자체들을 기준으로 라인별 정렬후 파일 s1.txt에 그 결과를 기록하는 코드를 작성하시오. 즉, 프로그램 수행 후 s1.txt에 있는 파일 내용은 다음과 같다.<br /><br />cat dog<br />dog pig<br />ham bird<br />pig ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "f1 = open('s.txt')\n",
    "L = f1.readlines()\n",
    "f1.close()\n",
    "L.sort()\n",
    "\n",
    "f2 = open('s1.txt', 'w')\n",
    "f2.writelines(L)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat dog\n",
      "dog pig\n",
      "ham bird\n",
      "pig ham\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('s1.txt')\n",
    "print f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.txt를 한 줄씩 읽은 후 리스트에 저장하여 해당 리스트를 sort하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####2) 파일 s.txt을 읽어서 각 라인에 있는 두 번째 단어(문자열) 자체들을 기준으로 라인별 정렬후 파일 s2.txt에 그 결과를 기록하는 코드를 작성하시오. 즉, 프로그램 수행 후 s2.txt에 있는 파일 내용은 다음과 같다.<br /><br />ham bird<br />cat dog<br />pig ham<br />dog pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cmp1(a, b) :\n",
    "    return cmp(a[4], b[4])\n",
    "\n",
    "\n",
    "f1 = open('s.txt')\n",
    "L = f1.readlines()\n",
    "f1.close()\n",
    "L.sort(cmp1)\n",
    "\n",
    "f2 = open('s2.txt', 'w')\n",
    "f2.writelines(L)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham bird\n",
      "cat dog\n",
      "pig ham\n",
      "dog pig\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('s2.txt')\n",
    "print f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.txt를 한 줄씩 읽은 후, 각 문자열들은 3개의 단어 2개가 합쳐진 것이므로 비교 대상을 2번째 단어의 첫 알파벳으로 하여 sort하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####3) 파일 s.txt을 읽어서 각 라인들에 있는 모든 단어들을 순차적으로 다시 나열하되 각 라인에 세 개의 단어들이 오도록 하여 s3.txt에 기록하는 코드를 작성하시오. 즉, 프로그램 수행 후 s3.txt에 있는 파일 내용은 다음과 같다.<br /><br />pig ham cat<br />dog ham bird<br />dog pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 = open('s.txt')\n",
    "wordsList = f1.read().split()\n",
    "s3List = []\n",
    "\n",
    "for x in range(len(wordsList)) :\n",
    "    s3List.append(wordsList[x])\n",
    "    if (x+1)%3 == 0 :\n",
    "        s3List.append('\\n')\n",
    "    else :\n",
    "        s3List.append(' ')\n",
    "\n",
    "f2 = open('s3.txt', 'w')\n",
    "f2.writelines(s3List)\n",
    "f2.close()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pig ham cat\n",
      "dog ham bird\n",
      "dog pig \n"
     ]
    }
   ],
   "source": [
    "f = open('s3.txt')\n",
    "print f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.txt를 한 줄씩 읽은 후 split()을 이용하여 각각의 단어별로 리스트에 저장하였다. 리스트에 저장한 단어들을 3개씩 끊어 s3.txt에 저장하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. 다음과 같은 조건들을 참고하여 회원 가입 및 로그인 프로그램을 작성하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####1) 프로그램 시작 후 다음과 같은 메시지가 출력되어 1, 2, 3 중 하나의 값을 입력 받도록 한다.<br /><br />Welcome to Our Service<br />1. Sign Up<br />2. Sign In<br />3. Quit\n",
    "\n",
    "####2) 1을 선택하면 ID, Password, Name, School의 4가지 정보를 입력받아 파일에 저장하는 프로그램을 작성한다.<br /><br />2-1) 입력된 내용은 access.txt 라는 이름의 텍스트 파일 내에 저장된다.<br />2-2) access.txt 파일의 각 라인에는 가입된 회원 각각의 정보가 \"[id]: [password], [name], [school]\" 형태로 저장된다.<br />2-3) 즉, 가입 회원이 10명이면 access.txt 파일 내에 라인 수도 정확히 10개이다.<br />2-4) 암호화 방식은 sha 모듈을 활용한다. sha 모듈 활용 방법은 본 문제의 마지막에 제시된 sha 활용 예를 참고한다.<br />즉, access.txt 파일 내에 password 정보는 암호화 되어 저장되어야 한다.<br />2-5) 회원 정보를 입력 받을 때 id를 입력 받은 직후 access.txt를 확인하여 이미 존재하는 id가 입력되었다면 다음 메시지를 출력하고 id 정보를 다시 입력받는다.<br />Sorry, the entered ID is already used.\n",
    "\n",
    "####3) 2를 선택하면 ID, Password의 2가지 정보를 입력받는 프로그램을 작성한다.<br /><br />3-1) 입력된 ID 정보가 access.txt에 존재하지 않으면 다음과 같은 메시지를 출력하고 다시 입력받는다.<br />Sorry, you are not a registered member.<br />3-2) 입력된 ID가 올바르게 존재하지만 Password 정보가 access.txt 파일에 있는 정보와 불일치하면 다음과 같은 메시지를 출력하고 Password를 다시 입력받는다.<br />Sorry, the entered password is not correct.<br />이 때에도 사용자가 입력한 Password 정보와 함께 sha 모듈이 활용되어야 한다.<br />3-3) 입력된 ID와 Password가 모두 올바르면 다음과 같은 메시지를 출력한다.<br />Hello [name]!<br />위 [name]에는 access.txt에 기록되어 있는 name 정보를 출력한다.\n",
    "\n",
    "####4) 3을 선택하면 프로그램이 끝난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Our Service\n",
      "\n",
      "1. Sign Up\n",
      "2. Sign In\n",
      "3. Quit\n",
      "\n",
      "Enter Number: 1\n",
      "\n",
      "Enter ID: ABC\n",
      "Enter Password: 1\n",
      "Enter Your Name: KIM\n",
      "Enter Your School Name: korea\n",
      "\n",
      "\n",
      "Enter Number: 1\n",
      "\n",
      "Enter ID: DEF\n",
      "Enter Password: 2\n",
      "Enter Your Name: CHEN\n",
      "Enter Your School Name: china\n",
      "\n",
      "\n",
      "Enter Number: 1\n",
      "\n",
      "Enter ID: OYA\n",
      "Enter Password: 3\n",
      "Enter Your Name: IKAJKA\n",
      "Enter Your School Name: japan\n",
      "\n",
      "\n",
      "Enter Number: 2\n",
      "\n",
      "Enter Your ID: DEF\n",
      "Enter Your Password: 1\n",
      "Sorry, the entered password is not correct.\n",
      "Enter Your Password: 2\n",
      "\n",
      "Hello DEF!,  User Name: CHEN, School: china\n",
      "\n",
      "Enter Number: 3\n",
      "\n",
      "Exit Program\n"
     ]
    }
   ],
   "source": [
    "import sha\n",
    "import os\n",
    "\n",
    "print ('Welcome to Our Service')\n",
    "print\n",
    "print ('1. Sign Up')\n",
    "print ('2. Sign In')\n",
    "print ('3. Quit')\n",
    "print\n",
    "\n",
    "while True :\n",
    "    num = input(\"Enter Number: \")\n",
    "    print\n",
    "\n",
    "    if num == 1 :\n",
    "        while True :\n",
    "            IDCheck = False\n",
    "\n",
    "            if os.path.exists('access.txt') == False :\n",
    "                f = open('access.txt', 'w')\n",
    "                f.close()\n",
    "\n",
    "            f = open('access.txt')\n",
    "\n",
    "\n",
    "            ID = raw_input(\"Enter ID: \")\n",
    "\n",
    "            for x in f :\n",
    "                if ID in (x.split(':'))[0] :\n",
    "                    print 'Sorry, the entered ID is already used.'\n",
    "                    IDCheck = True\n",
    "                    break\n",
    "\n",
    "            if IDCheck == True :\n",
    "                continue\n",
    "            else :\n",
    "                break\n",
    "\n",
    "        password = raw_input(\"Enter Password: \")\n",
    "        name = raw_input(\"Enter Your Name: \")\n",
    "        school = raw_input(\"Enter Your School Name: \")\n",
    "        #비밀번호 암호화\n",
    "        password_encrypted = sha.new(password).hexdigest()\n",
    "        print\n",
    "        print\n",
    "\n",
    "        f2 = open('access.txt', 'a')\n",
    "        f2.write(ID+':'+' '+password_encrypted+', '+name+', '+school+'\\n')\n",
    "        f2.close()\n",
    "\n",
    "    elif num == 2 :\n",
    "        notuse = False\n",
    "        infoList = []\n",
    "\n",
    "        while True :\n",
    "            IDCheck = False\n",
    "\n",
    "            if os.path.exists('access.txt') == False :\n",
    "                print 'No one is registered.'\n",
    "                notuse = True\n",
    "                break\n",
    "\n",
    "            else :\n",
    "                f = open('access.txt')\n",
    "\n",
    "                ID = raw_input(\"Enter Your ID: \")\n",
    "\n",
    "                for x in f :\n",
    "                    if ID in (x.split(':'))[0] :\n",
    "                        IDCheck = True\n",
    "                        usrInfo = x.split(':')[1]\n",
    "                        usrPW = usrInfo.split(',')[0][1:]\n",
    "                        break\n",
    "\n",
    "                if IDCheck == True :\n",
    "                    break\n",
    "                else :\n",
    "                    print 'Sorry, you are not a registered member.'\n",
    "                    continue\n",
    "        if notuse == True :\n",
    "            continue\n",
    "        else :\n",
    "            while True :\n",
    "                #PWCheck = False\n",
    "\n",
    "                password = raw_input(\"Enter Your Password: \")\n",
    "\n",
    "                if usrPW == sha.new(password).hexdigest() :\n",
    "                    break\n",
    "                else :\n",
    "                    print 'Sorry, the entered password is not correct.'\n",
    "\n",
    "        print\n",
    "        print 'Hello ' + ID + '!,  User Name: ' + usrInfo.split(',')[1][1:] + ', School: ' + usrInfo.split(',')[2][1:]\n",
    "\n",
    "    elif num == 3 :\n",
    "        print 'Exit Program'\n",
    "        break\n",
    "\n",
    "    else :\n",
    "        print \"input error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파일에서 읽은 내용들을 한 줄씩 split()을 이용하여 ':'을 기준으로 분리하였다. 분리를 하면 결과값이 리스트 형식으로 나오는데, 리스트의 0번째 인덱스에는 저장된 ID가, 리스트의 1번째 인덱스에는 해당 ID의 정보들이 입력된다.\n",
    "- 위와 같은 방식으로 입력 받은 ID를 'x in A'구문을 사용하여 존재하는지 파악하였고, 로그인 시 해당 ID가 access.txt.에 존재한다면 split(':')으로 분리하여 나온 결과 리스트의 1번째 인덱스들을 다시 split(',')을 이용하여 분리해주었다. 때문에 split(',')의 결과로 생성된 리스트의 0번째 인덱스는 비밀번호를 나타내므로 이를 이용하여 입력된 비밀번호와 저장된 비밀번호가 일치하는지 체크하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. range() 함수와 유사한 frange() 함수를 다음 조건을 참고하여 만드시오.\n",
    "\n",
    "####1) frange()의 인자 구성은 다음과 같이 range와 동일하지만 각 인수들은 음수를 받지 않는다고 가정한다.\n",
    "#####range(stop)\n",
    "#####range(start, stop[, step])\n",
    "####2) frange() 함수의 인자에 대한 기본 시작(start) 값은 0.0이고, 기본 단계(step) 값은 0.1이다.<br /><br />3) frange 사용 예\n",
    "#####3-1) frange(0.5)\n",
    "#####[0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "#####3-2) frange(1.0, 2.0)\n",
    "#####[1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]\n",
    "#####3-3) frange(2.2, 4.0, 0.5)\n",
    "#####[2.2, 2.7, 3.2, 3.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def frange(*arg) :\n",
    "    if len(arg) == 1 :\n",
    "        return cal_frange(stop = arg[0])\n",
    "    elif len(arg) == 2 :\n",
    "        return cal_frange(start = arg[0], stop = arg[1])\n",
    "    elif len(arg) == 3 :\n",
    "        return cal_frange(start = arg[0], stop = arg[1], step = arg[2])\n",
    "    else :\n",
    "        print \"error input\"\n",
    "        \n",
    "def cal_frange(stop, start=0.0, step=0.1) :\n",
    "    L = []\n",
    "    \n",
    "    while start < stop :\n",
    "        i = int(start * 10)\n",
    "        x = i/10.0\n",
    "        L.append(x)\n",
    "        start = start + step\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.1, 0.2, 0.3, 0.4]\n",
      "[1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]\n",
      "[2.2, 2.7, 3.2, 3.7]\n"
     ]
    }
   ],
   "source": [
    "print frange(0.5)\n",
    "print frange(1.0, 2.0)\n",
    "print frange(2.2, 4.0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frange()에 가변 인수를 선언하여 변수의 갯수에 맞추어 각각을 정의해준다. 각각의 경우들을 계산해주는 (계산)함수를 다시 선언해주어 결과 값이 출력되게 해주었다.\n",
    "* cal_frange()함수의 내부를 살펴보면 i = int(start*10), x = i/10.0 부분이 존재하는데 이 두 문장을 제외하고 그냥 start를 L에 추가하면 frange()의 결과로 소수점 2번째 자리 이상의 수들이 출력되어, 출력되는 자릿수를 맞추기 위해 해당 두 문장을 추가하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. 가변인수를 받는 함수 sum()을 다음과 같은 조건을 참고하여 구현하시오.\n",
    "\n",
    "####sum() 사용 예\n",
    "####sum()<br />0\n",
    "####sum(1, 2)<br />3\n",
    "####sum(1, 2, 3, 4, 5)<br />15\n",
    "####sum(1, 5, 7, 2, -10)<br />5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum(*args) :\n",
    "    result = 0\n",
    "    \n",
    "    for x in args :\n",
    "        result += x\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "15\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print sum()\n",
    "print sum(1, 2)\n",
    "print sum(1, 2, 3, 4, 5)\n",
    "print sum(1, 5, 7, 2, -10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum()함수를 정의할 때 가변 인수를 사용하여 입력받는 인수의 갯수에 상관없이 결과 값을 출력하도록 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5.여러 단어로 이루어진 문자열을 입력받아 각 단어의 첫글자로 이루어진 단어를 대문자로 출력하는 myinitial() 함수를 다음 조건을 참고하여 작성하시오.\n",
    "####1) 다음에 제시되는 함수들을 모두 이용해야 한다.<br />split<br />map<br />join\n",
    "####2) myinitial() 함수 사용 예<br />myinitial(\"as soon as possible\")<br />ASAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myinitial(strs) :\n",
    "    return ''.join(map(lambda x: x[0].upper(), strs.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASAP\n"
     ]
    }
   ],
   "source": [
    "print myinitial(\"as soon as possible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력받은 문자열들을 공백을 기준으로 분리한 후 각각의 인덱스가 가리키는 첫번째 문자들을 대문자로 바꾸어 준 후 join을 이용하여 이들을 묶어주었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###6. 음이 아닌 정수 n를 입력받으면 n! (factorial)을 계산하는 myfact() 함수를 재귀적 함수로 구현하시오.\n",
    "\n",
    "####[옵션] 참을 수 있는 정도 만큼의 수행시간을 직접 기다려보면서 n을 늘려보도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myfact(n) :\n",
    "    if n == 0 or n == 1 :\n",
    "        return 1\n",
    "    elif n > 1 :\n",
    "        return n*myfact(n-1)\n",
    "    else :\n",
    "        print \"input error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "15511210043330985984000000\n",
      "188267717688892609974376770249160085759540364871492425887598231508353156331613598866882932889495923133646405445930057740630161919341380597818883457558547055524326375565007131770880000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "print myfact(5)\n",
    "print myfact(25)\n",
    "print myfact(125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 n을 입력시 재귀적 함수를 이용하여 n과 myfact(n-1)을 곱해주도록 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7. (서술형) import string 과 from string import * 의 차이점을 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import string은 string 모듈을 현재 공간에 사용(import)한다는 것이다. string 모듈 안에 정의되어있는 x라는 함수를 사용하기 위해서는 string.x()의 형식으로 사용하여야 한다.<br />\n",
    "from string import *은 string 모듈에 존재하는 '__'로 시작되는 이름들을 제외한 모든 이름들을 현재의 공간으로 가져오는 것이다. 예를들어 string 모듈 내에 정의되어있는 x라는 함수는 그냥 x()의 형식으로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###8. 10 이하의 소수를 모두 더하면 2 + 3 + 5 + 7 = 17 이 됩니다. <br />이백만(2,000,000) 이하 소수의 합은 얼마입니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142913828922\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "num = 2000000\n",
    "n_sum= 5\n",
    "x = 4\n",
    "\n",
    "while x <= num :\n",
    "    k = math.sqrt(x)\n",
    "    check = True\n",
    "    \n",
    "    for y in range(2, int(k)+1) :\n",
    "        if x % y == 0 :\n",
    "            check = False\n",
    "            break\n",
    "    \n",
    "    if check == False:\n",
    "        x = x + 1\n",
    "    else :\n",
    "        n_sum = n_sum + x\n",
    "        x = x + 1\n",
    "            \n",
    "print n_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 앞의 과제에서 사용한 2, 3중의 for()구문을 이용한 소수찾기는 범위가 커지면 처리 시간이 매우 느려진다는 단점이 있었다. 때문에 이번 문제의 답을 구할 수 없었다. 그래서 소수를 판별하는 효율적인 방법을 찾아 이용하였다.(제곱근을 이용한 방법)<br />\n",
    "해당 수를 제곱근으로 나누어 2부터 제곱근을 씌운 값까지 나누어진다면 다음 소수를 찾기로 하였고, 나누어지는 수가 없으면(약수는 1과 자기 자신뿐) 해당 수를 소수로 판별하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###9. 아래와 같은 20×20 격자가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "08 02 22 97 38 15 00 40 00 75 04 05 07 78 52 12 50 77 91 08<br />\n",
    "49 49 99 40 17 81 18 57 60 87 17 40 98 43 69 48 04 56 62 00<br />\n",
    "81 49 31 73 55 79 14 29 93 71 40 67 53 88 30 03 49 13 36 65<br />\n",
    "52 70 95 23 04 60 11 42 69 24 68 56 01 32 56 71 37 02 36 91<br />\n",
    "22 31 16 71 51 67 63 89 41 92 36 54 22 40 40 28 66 33 13 80<br />\n",
    "24 47 32 60 99 03 45 02 44 75 33 53 78 36 84 20 35 17 12 50<br />\n",
    "32 98 81 28 64 23 67 10 26 38 40 67 59 54 70 66 18 38 64 70<br />\n",
    "67 26 20 68 02 62 12 20 95 63 94 39 63 08 40 91 66 49 94 21<br />\n",
    "24 55 58 05 66 73 99 26 97 17 78 78 96 83 14 88 34 89 63 72<br />\n",
    "21 36 23 09 75 00 76 44 20 45 35 14 00 61 33 97 34 31 33 95<br />\n",
    "78 17 53 28 22 75 31 67 15 94 03 80 04 62 16 14 09 53 56 92<br />\n",
    "16 39 05 42 96 35 31 47 55 58 88 24 00 17 54 24 36 29 85 57<br />\n",
    "86 56 00 48 35 71 89 07 05 44 44 37 44 60 21 58 51 54 17 58<br />\n",
    "19 80 81 68 05 94 47 69 28 73 92 13 86 52 17 77 04 89 55 40<br />\n",
    "04 52 08 83 97 35 99 16 07 97 57 32 16 26 26 79 33 27 98 66<br />\n",
    "88 36 68 87 57 62 20 72 03 46 33 67 46 55 12 32 63 93 53 69<br />\n",
    "04 42 16 73 38 25 39 11 24 94 72 18 08 46 29 32 40 62 76 36<br />\n",
    "20 69 36 41 72 30 23 88 34 62 99 69 82 67 59 85 74 04 36 16<br />\n",
    "20 73 35 29 78 31 90 01 74 31 49 71 48 86 81 16 23 57 05 54<br />\n",
    "01 70 54 71 83 51 54 69 16 92 33 48 61 43 52 01 89 19 67 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###위에서 대각선 방향으로 연속된 붉은 숫자 네 개의 곱은 26 × 63 × 78 × 14 = 1788696 입니다.<br />그러면 수평, 수직, 또는 대각선 방향으로 연속된 숫자 네 개의 곱 중 최대값은 얼마입니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = [['08', '02', '22', '97', '38', '15', '00', '40' ,'00', '75', '04', '05', '07', '78', '52', '12', '50', '77', '91', '08'],\n",
    "           ['49', '49', '99', '40', '17', '81', '18', '57', '60', '87', '17', '40', '98', '43', '69', '48', '04', '56', '62', '00'],\n",
    "           ['81', '49', '31', '73', '55', '79', '14', '29', '93', '71', '40', '67', '53', '88', '30', '03', '49', '13', '36', '65'],\n",
    "           ['52', '70', '95', '23', '04', '60', '11', '42', '69', '24', '68', '56', '01', '32', '56', '71', '37', '02', '36', '91'],\n",
    "           ['22', '31', '16', '71', '51', '67', '63', '89', '41', '92', '36', '54', '22', '40', '40', '28', '66', '33', '13', '80'],\n",
    "           ['24', '47', '32', '60', '99', '03', '45', '02', '44', '75', '33', '53', '78', '36', '84', '20', '35', '17', '12', '50'],\n",
    "           ['32', '98', '81', '28', '64', '23', '67', '10', '26', '38', '40', '67', '59', '54', '70', '66', '18', '38', '64', '70'],\n",
    "           ['67', '26', '20', '68', '02', '62', '12', '20', '95', '63', '94', '39', '63', '08', '40', '91', '66', '49', '94', '21'],\n",
    "           ['24', '55', '58', '05', '66', '73', '99', '26', '97', '17', '78', '78', '96', '83', '14', '88', '34', '89', '63', '72'],\n",
    "           ['21', '36', '23', '09', '75', '00', '76', '44', '20', '45', '35', '14', '00', '61', '33', '97', '34', '31', '33', '95'],\n",
    "           ['78', '17', '53', '28', '22', '75', '31', '67', '15', '94', '03', '80', '04', '62', '16', '14', '09', '53', '56', '92'],\n",
    "           ['16', '39', '05', '42', '96', '35', '31', '47', '55', '58', '88', '24', '00', '17', '54', '24', '36', '29', '85', '57'],\n",
    "           ['86', '56', '00', '48', '35', '71', '89', '07', '05', '44', '44', '37', '44', '60', '21', '58', '51', '54', '17', '58'],\n",
    "           ['19', '80', '81', '68', '05', '94', '47', '69', '28', '73', '92', '13', '86', '52', '17', '77', '04', '89', '55', '40'],\n",
    "           ['04', '52', '08', '83', '97', '35', '99', '16', '07', '97', '57', '32', '16', '26', '26', '79', '33', '27', '98', '66'],\n",
    "           ['88', '36', '68', '87', '57', '62', '20', '72', '03', '46', '33', '67', '46', '55', '12', '32', '63', '93', '53', '69'],\n",
    "           ['04', '42', '16', '73', '38', '25', '39', '11', '24', '94', '72', '18', '08', '46', '29', '32', '40', '62', '76', '36'],\n",
    "           ['20', '69', '36', '41', '72', '30', '23', '88', '34', '62', '99', '69', '82', '67', '59', '85', '74', '04', '36', '16'],\n",
    "           ['20', '73', '35', '29', '78', '31', '90', '01', '74', '31', '49', '71', '48', '86', '81', '16', '23', '57', '05', '54'],\n",
    "           ['01', '70', '54', '71', '83', '51', '54', '69', '16', '92', '33', '48', '61', '43', '52', '01', '89', '19', '67', '48']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_horizon(n) :\n",
    "    hor_max = 0\n",
    "    for i in range(20) :\n",
    "        for j in range(20) :\n",
    "            if j >= 17 :\n",
    "                break\n",
    "            else :\n",
    "                mul = int(n[i][j]) * int(n[i][j+1]) * int(n[i][j+2]) * int(n[i][j+3])\n",
    "                hor_max = mul if mul>hor_max else hor_max\n",
    "            \n",
    "    return hor_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_vertical(n) :\n",
    "    ver_max = 0\n",
    "    for j in range(20) :\n",
    "        for i in range(20) :\n",
    "            if i >= 17 :\n",
    "                break\n",
    "            else :\n",
    "                mul = int(n[i][j]) * int(n[i+1][j]) * int(n[i+2][j]) * int(n[i+3][j])\n",
    "                ver_max = mul if mul>ver_max else ver_max\n",
    "                \n",
    "    return ver_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_lrcross(n) :\n",
    "    lr_max = 0\n",
    "    for i in range(20) :\n",
    "        if i >= 17 :\n",
    "            break\n",
    "        for j in range(20) :\n",
    "            if j >= 17 :\n",
    "                break\n",
    "            else :\n",
    "                mul = int(n[i][j]) * int(n[i+1][j+1]) * int(n[i+2][j+2]) * int(n[i+3][j+3])\n",
    "                lr_max = mul if mul>lr_max else lr_max\n",
    "                \n",
    "    return lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_rlcross(n) :\n",
    "    rl_max = 0\n",
    "    for i in range(20) :\n",
    "        if i >= 17 :\n",
    "            break\n",
    "        for j in range(3, 20) :\n",
    "            if j >= 17 :\n",
    "                break\n",
    "            else :\n",
    "                mul = int(n[i][j]) * int(n[i+1][j-1]) * int(n[i+2][j-2]) * int(n[i+3][j-3])\n",
    "                rl_max = mul if mul>rl_max else rl_max\n",
    "                \n",
    "    return rl_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70600674\n"
     ]
    }
   ],
   "source": [
    "a = multi_horizon(numbers)\n",
    "b = multi_vertical(numbers)\n",
    "c = multi_lrcross(numbers)\n",
    "d = multi_rlcross(numbers)\n",
    "max_num = []\n",
    "max_num.append(a); max_num.append(b); max_num.append(c); max_num.append(d);\n",
    "max_num.sort(reverse=True)\n",
    "\n",
    "print max_num[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 수들을 2차원 배열 형식으로 저장하였다. 가로, 세로, /대각선, /의 역대각선 별로 덧셈을 하여 가장 큰 수를 찾아내는 함수를 정의하였으며 4개의 각각의 결과들을 리스트에 저장하여 정렬하여 가장 큰 값을 찾아내었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###10. 1부터 n까지의 자연수를 차례로 더하여 구해진 값을 삼각수라고 합니다.<br />예를 들어 7번째 삼각수는 1 + 2 + 3 + 4 + 5 + 6 + 7 = 28이 됩니다.<br />이런 식으로 삼각수를 구해 나가면 다음과 같습니다.<br />1, 3, 6, 10, 15, 21, 28, 36, 45, 55, ... <br />이 삼각수들의 약수를 구해봅시다. <br />1: 1<br /> 3: 1, 3<br /> 6: 1, 2, 3, 6<br />10: 1, 2, 5, 10<br />15: 1, 3, 5, 15<br />21: 1, 3, 7, 21<br />28: 1, 2, 4, 7, 14, 28<br />위에서 보듯이, 5개 이상의 약수를 갖는 첫번째 삼각수는 28입니다.<br />그러면 500개 이상의 약수를 갖는 가장 작은 삼각수는 얼마입니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76576500\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def divisor(tn):\n",
    "    d_number = 1 #모든 수는 1로 나누어 지기 때문에\n",
    "                 #range범위를 (1,x)로 해주어야 한다. 나누는 수가 0이 될 수 없으니까\n",
    "\n",
    "    k = math.sqrt(tn)\n",
    "    \n",
    "    for i in xrange(1, int(k)+1):\n",
    "        if tn%i == 0:\n",
    "            d_number = d_number + 1\n",
    "        \n",
    "    return d_number*2\n",
    "\n",
    "check = 2\n",
    "\n",
    "while True:\n",
    "\n",
    "    tri_number = check*(check+1)/2    \n",
    "\n",
    "    if divisor(tri_number) >= 500:\n",
    "        print tri_number\n",
    "        break\n",
    "\n",
    "    check = check + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###11. 아래에 50자리 숫자가 100개 있습니다. 이것을 모두 더한 값의 첫 10자리는 얼마입니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = [37107287533902102798797998220837590246510135740250,\n",
    "46376937677490009712648124896970078050417018260538,\n",
    "74324986199524741059474233309513058123726617309629,\n",
    "91942213363574161572522430563301811072406154908250,\n",
    "23067588207539346171171980310421047513778063246676,\n",
    "89261670696623633820136378418383684178734361726757,\n",
    "28112879812849979408065481931592621691275889832738,\n",
    "44274228917432520321923589422876796487670272189318,\n",
    "47451445736001306439091167216856844588711603153276,\n",
    "70386486105843025439939619828917593665686757934951,\n",
    "62176457141856560629502157223196586755079324193331,\n",
    "64906352462741904929101432445813822663347944758178,\n",
    "92575867718337217661963751590579239728245598838407,\n",
    "58203565325359399008402633568948830189458628227828,\n",
    "80181199384826282014278194139940567587151170094390,\n",
    "35398664372827112653829987240784473053190104293586,\n",
    "86515506006295864861532075273371959191420517255829,\n",
    "71693888707715466499115593487603532921714970056938,\n",
    "54370070576826684624621495650076471787294438377604,\n",
    "53282654108756828443191190634694037855217779295145,\n",
    "36123272525000296071075082563815656710885258350721,\n",
    "45876576172410976447339110607218265236877223636045,\n",
    "17423706905851860660448207621209813287860733969412,\n",
    "81142660418086830619328460811191061556940512689692,\n",
    "51934325451728388641918047049293215058642563049483,\n",
    "62467221648435076201727918039944693004732956340691,\n",
    "15732444386908125794514089057706229429197107928209,\n",
    "55037687525678773091862540744969844508330393682126,\n",
    "18336384825330154686196124348767681297534375946515,\n",
    "80386287592878490201521685554828717201219257766954,\n",
    "78182833757993103614740356856449095527097864797581,\n",
    "16726320100436897842553539920931837441497806860984,\n",
    "48403098129077791799088218795327364475675590848030,\n",
    "87086987551392711854517078544161852424320693150332,\n",
    "59959406895756536782107074926966537676326235447210,\n",
    "69793950679652694742597709739166693763042633987085,\n",
    "41052684708299085211399427365734116182760315001271,\n",
    "65378607361501080857009149939512557028198746004375,\n",
    "35829035317434717326932123578154982629742552737307,\n",
    "94953759765105305946966067683156574377167401875275,\n",
    "88902802571733229619176668713819931811048770190271,\n",
    "25267680276078003013678680992525463401061632866526,\n",
    "36270218540497705585629946580636237993140746255962,\n",
    "24074486908231174977792365466257246923322810917141,\n",
    "91430288197103288597806669760892938638285025333403,\n",
    "34413065578016127815921815005561868836468420090470,\n",
    "23053081172816430487623791969842487255036638784583,\n",
    "11487696932154902810424020138335124462181441773470,\n",
    "63783299490636259666498587618221225225512486764533,\n",
    "67720186971698544312419572409913959008952310058822,\n",
    "95548255300263520781532296796249481641953868218774,\n",
    "76085327132285723110424803456124867697064507995236,\n",
    "37774242535411291684276865538926205024910326572967,\n",
    "23701913275725675285653248258265463092207058596522,\n",
    "29798860272258331913126375147341994889534765745501,\n",
    "18495701454879288984856827726077713721403798879715,\n",
    "38298203783031473527721580348144513491373226651381,\n",
    "34829543829199918180278916522431027392251122869539,\n",
    "40957953066405232632538044100059654939159879593635,\n",
    "29746152185502371307642255121183693803580388584903,\n",
    "41698116222072977186158236678424689157993532961922,\n",
    "62467957194401269043877107275048102390895523597457,\n",
    "23189706772547915061505504953922979530901129967519,\n",
    "86188088225875314529584099251203829009407770775672,\n",
    "11306739708304724483816533873502340845647058077308,\n",
    "82959174767140363198008187129011875491310547126581,\n",
    "97623331044818386269515456334926366572897563400500,\n",
    "42846280183517070527831839425882145521227251250327,\n",
    "55121603546981200581762165212827652751691296897789,\n",
    "32238195734329339946437501907836945765883352399886,\n",
    "75506164965184775180738168837861091527357929701337,\n",
    "62177842752192623401942399639168044983993173312731,\n",
    "32924185707147349566916674687634660915035914677504,\n",
    "99518671430235219628894890102423325116913619626622,\n",
    "73267460800591547471830798392868535206946944540724,\n",
    "76841822524674417161514036427982273348055556214818,\n",
    "97142617910342598647204516893989422179826088076852,\n",
    "87783646182799346313767754307809363333018982642090,\n",
    "10848802521674670883215120185883543223812876952786,\n",
    "71329612474782464538636993009049310363619763878039,\n",
    "62184073572399794223406235393808339651327408011116,\n",
    "66627891981488087797941876876144230030984490851411,\n",
    "60661826293682836764744779239180335110989069790714,\n",
    "85786944089552990653640447425576083659976645795096,\n",
    "66024396409905389607120198219976047599490197230297,\n",
    "64913982680032973156037120041377903785566085089252,\n",
    "16730939319872750275468906903707539413042652315011,\n",
    "94809377245048795150954100921645863754710598436791,\n",
    "78639167021187492431995700641917969777599028300699,\n",
    "15368713711936614952811305876380278410754449733078,\n",
    "40789923115535562561142322423255033685442488917353,\n",
    "44889911501440648020369068063960672322193204149535,\n",
    "41503128880339536053299340368006977710650566631954,\n",
    "81234880673210146739058568557934581403627822703280,\n",
    "82616570773948327592232845941706525094512325230608,\n",
    "22918802058777319719839450180888072429661980811197,\n",
    "77158542502016545090413245809786882778948721859617,\n",
    "72107838435069186155435662884062257473692284509516,\n",
    "20849603980134001723930671666823555245252804609722,\n",
    "53503534226472524250874054075591789781264330331690]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5537376230\n"
     ]
    }
   ],
   "source": [
    "#50자리의 수를 100번 더하여도 최대자리수는 52이다.\n",
    "z_str = '1' + '0'*42\n",
    "z_int = long(z_str)\n",
    "\n",
    "ssum = sum(x for x in numbers)\n",
    "    \n",
    "print ssum/z_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50자리의 수를 100번 더하여도 결과 값의 자릿수는 51 또는 52자리이다. 때문에 각각의 수를 더한 값들을 10의 배수 중 0이 41개인 또는 42개인 수로 나누어주면 앞부분의 첫 10자리가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###12. 양의 정수 n에 대하여, 다음과 같은 계산 과정을 반복하기로 합니다.<br /><br />n → n / 2 (n이 짝수일 때)<br />n → 3 n + 1 (n이 홀수일 때)<br /><br />13에 대하여 위의 규칙을 적용해보면 아래처럼 10번의 과정을 통해 1이 됩니다.<br /><br />13 → 40 → 20 → 10 → 5 → 16 → 8 → 4 → 2 → 1<br /><br />아직 증명은 되지 않았지만, 이런 과정을 거치면 어떤 수로 시작해도 마지막에는 1로 끝나리라 생각됩니다. <br />(역주: 이것은 콜라츠 추측 Collatz Conjecture이라고 하며, 이런 수들을 우박수 hailstone sequence라 부르기도 합니다)<br /><br />그러면, 백만(1,000,000) 이하의 수로 시작했을 때 1까지 도달하는데 가장 긴 과정을 거치는 숫자는 얼마입니까?<br />참고: 계산 과정 도중에는 숫자가 백만을 넘어가도 괜찮습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collatz_conjecture(i, count=0) :\n",
    "    \n",
    "    if i % 2 == 0 :\n",
    "        i = i/2\n",
    "        count = count + 1\n",
    "        return collatz_conjecture(i, count)\n",
    "    elif i == 1 :\n",
    "        return count\n",
    "    else :\n",
    "        count = count + 1\n",
    "        i = 3*i + 1  \n",
    "        return collatz_conjecture(i, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number:  524 count:  837799\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "cnt_result = 1\n",
    "\n",
    "while k <= 1000000 :\n",
    "    cnt = collatz_conjecture(k)\n",
    "    \n",
    "    if cnt > cnt_result :\n",
    "        cnt_result = cnt\n",
    "        number = k\n",
    "        \n",
    "    k = k + 1\n",
    "        \n",
    "print 'number: ', \n",
    "print cnt_result, \n",
    "print 'count: ',\n",
    "print number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collatz_conjecture(i, count)에서 i는 판별할 수를 나타내고 count는 계산 횟수를 나타낸다. 함수를 살펴보면 입력받은 수가 홀수, 짝수에 따라 계산이 되어지며 1이 되면 count만을 return하게 된다. 따라서 main함수에서는 계산 횟수만을 비교하여 백만 이하 수들 중, 1까지 도달하는데 가장 긴 과정을 거치는 수를 찾게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###13. 아래와 같은 2 × 2 격자의 왼쪽 위 모서리에서 출발하여 오른쪽 아래 모서리까지 도달하는 길은 모두 6가지가 있습니다 (거슬러 가지는 않기로 합니다).<br /><br />그러면 20 × 20 격자에는 모두 몇 개의 경로가 있습니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137846528820\n"
     ]
    }
   ],
   "source": [
    "def fact(num):\n",
    "    if num == 1 :\n",
    "        return 1\n",
    "    return num * fact(num-1)\n",
    "\n",
    "i = fact(40) / (fact(20) * fact(20))\n",
    "\n",
    "print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고등학교 때 배운 순열과 조합을 생각하면 쉽게 문제가 풀린다. 위의 문제는 40C20으로 표현가능하므로 이를 식으로 만들어 문제를 해결하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###14. 이전 Assignment 3의 마지막 문제는 웹 URL로 지정된 웹페이지를 문자열로 가져와 모든 HTML 태그 및 CSS와 Javascript를 제외한 순수 텍스트를 얻어내고 그 안에 존재하는 단어를 추출하여 각 단어들에 대해 출현빈도를 사전형태({'world': 2, 'hello': 1, 'python': 1})로 저장하여 출력하는 것이었다. 이번에는 Assignment 3를 확장하여 다음과 같은 조건을 만족하도록 구현하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 다음 사이트에서 제시되는 영어 불용어를 참고하여 이전 숙제에서 구성했던 단어 사전에서 영어 불용어들을 모두 제거하는 코드를 추가하시오.<br />\n",
    "http://egloos.zum.com/wyb330/v/3029348<br />\n",
    "영어 불용어: [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']<br /><br />\n",
    "\n",
    "2) 각 URL로 지정된 웹페이지의 HTML 소스를 파일로 저장하시오.<br />\n",
    "URL이 http://URL 이라면 파일명은 URL.html 이다.<br />\n",
    "예: URL이 http://www.cnn.com 이라면 파일명은 www.cnn.com.html 이다.<br /><br />\n",
    "\n",
    "3) 단어의 출현빈도가 담긴 사전 객체를 위 HTML 소스 파일과 동일한 폴더에 파일로 저장하시오.<br />\n",
    "파일입출력 (E-learning 13주차) 마지막에 학습한 pickle 모듈을 활용하시오.<br />\n",
    "URL이 http://URL 이라면 사전 객체를 담고 있는 파일명은 URL.words.frequency 이다.<br />\n",
    "예: URL이 http://www.cnn.com 이라면 파일명은 www.cnn.com.words.frequency 이다.<br /><br />\n",
    "\n",
    "4) 최소 5개 이상의 영어 웹 사이트에 대한 HTML 소스 파일과 단어 출현빈도 파일을 저장하시오.<br />\n",
    "즉, 총 10개의 파일을 동일한 폴더에 생성하시오.<br />\n",
    "[주의] 영어 웹사이트 URL로만 5개 이상<br /><br />\n",
    "\n",
    "5) 위 문제에서 저장한 모든 words.frequency 파일들을 객체로 다시 로드하여 본인이 저장하여 분석한 사이트들에서 가장 많이 출현한 단어 3개를 뽑아 제시하시오.<br />\n",
    "반드시 pickle 모듈로 저장한 5개 이상의 words.frequency를 다시 5개 이상의 사전 객체로 로드 하는 코드가 추가되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import string\n",
    "import string\n",
    "\n",
    "punc = string.punctuation\n",
    "\n",
    "source = urllib2.urlopen(\"http://nytimes.com/\").read()\n",
    "real_source = source\n",
    "#print source3\n",
    "\n",
    "for i in range(0, source.count('<script')) :\n",
    "    if source.find('<script') != -1 :\n",
    "        source=source.replace(source[source.find('<script'):source.find('</script>')+9],\"\")\n",
    "        \n",
    "for i in range(0, source.count('<style')) :\n",
    "    if source.find('<style') != -1 :\n",
    "        source=source.replace(source[source.find('<style'):source.find('</style>')+8],\"\")\n",
    "\n",
    "for i in range(0, source.count('<!--')):\n",
    "    if source.find(\"<!--\") != -1:\n",
    "        source = source.replace(source[source.find(\"<!--\"):source.find(\"-->\")+3:],\"\")\n",
    "        \n",
    "for i in range(0,source.count(\"<\")):\n",
    "    if source.find(\"<\") != -1:\n",
    "        source = source.replace(source[source.find(\"<\"):source.find(\">\")+1:],\"\")\n",
    "        \n",
    "words = source.split()\n",
    "\n",
    "delPuncList = []\n",
    "puncStr = ''\n",
    "\n",
    "# punctuation(구두문자) 제거\n",
    "\n",
    "for x in words:\n",
    "    puncStr = ''\n",
    "    for y in x:\n",
    "        if y in punc :\n",
    "            puncStr = puncStr + ''\n",
    "        else :\n",
    "            puncStr = puncStr + y\n",
    "    delPuncList.append(puncStr)\n",
    "    \n",
    "# 구두문자 제거 후 출력\n",
    "#for x in delPuncList :\n",
    "#    print x\n",
    "\n",
    "NSpaceList = []\n",
    "\n",
    "#공백문자 제거\n",
    "for x in delPuncList :\n",
    "    if x in string.whitespace :\n",
    "        pass\n",
    "    else :\n",
    "        NSpaceList.append(x)\n",
    "\n",
    "#공백문자 제거 후 출력        \n",
    "#for x in NSpaceList :\n",
    "#   print x\n",
    "    \n",
    "#단어 빈도수 확인\n",
    "nytimes_dic = {}\n",
    "\n",
    "for x in NSpaceList :\n",
    "    nytimes_dic[x] = NSpaceList.count(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopWords = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', \n",
    "              'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']\n",
    "\n",
    "delStopWordList = []\n",
    "\n",
    "for word in NSpaceList :\n",
    "    if word in stopWords :\n",
    "        pass\n",
    "    else :\n",
    "        delStopWordList.append(word)\n",
    "\n",
    "#불용성 영어단어 제거        \n",
    "#for x in delStopWordList :\n",
    "#    print x\n",
    "\n",
    "#불용성 영단어 제거 후 단어 빈도수 확인\n",
    "nytimes_dic = {}\n",
    "\n",
    "for x in delStopWordList :\n",
    "    nytimes_dic[x] = delStopWordList.count(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('nytimes.com.html', 'w')\n",
    "f.write(real_source)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 단어의 출현빈도가 담긴 사전 객체를 위 HTML 소스 파일과 동일한 폴더에 파일로 저장하시오.\n",
    "파일입출력 (E-learning 13주차) 마지막에 학습한 pickle 모듈을 활용하시오.\n",
    "URL이 http://URL 이라면 사전 객체를 담고 있는 파일명은 URL.words.frequency 이다.\n",
    "예: URL이 http://www.cnn.com 이라면 파일명은 www.cnn.com.words.frequency 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ Sell : 1, all : 2, G20 : 1, caused : 1, Night : 1, NYT : 3, Cadillac’s : 1, More : 6, NYC : 3, creative : 1, ERIC : 1, Mortality : 1, AMY : 1, Least : 1, Angelina : 1, Business : 4, WAS : 1, Watch : 1, editors : 1, Grief : 1, 0 : 1, Nytimescom : 1, Western : 1, ‘Did : 1, Not : 4, Cases : 1, Now : 6, 348 : 1, Day : 4, ADAM : 1, Rousey : 1, Angus : 1, Senator : 1, BYU : 1, Sale : 4, AttacksNYT : 1, Celebrations : 1, Tech : 3, Wheels : 1, Feeling : 1, Where : 1, Jersey : 1, Feedback : 1, tickets : 1, shock : 1, Tax : 2, Trail : 1, FRANCE : 1, large : 1, Disguise : 1, Pitt’s : 1, Go : 4, Soldiers : 2, He : 1, Debate : 5, Chase : 1, Turkey : 1, Index : 1, UFC : 1, who’s : 1, FAUSSET : 1, Selves : 1, Familiar : 2, Vegetables : 1, Accent : 1, Cuban : 2, State : 2, Version : 1, video : 1, Finding : 1, Theater : 3, Instamom : 2, bake : 1, Sections : 3, Available : 1, Steely : 1, what : 1, SCHREUER : 1, appear : 1, consumers : 1, Subscriptions : 5, Bruce : 1, fivebedroom : 1, crust : 1, week’s : 2, find : 1, crush : 1, siege : 1, Assault : 2, Link : 1, new : 1, Line : 2, Wit : 1, Heavy : 1, Deductibles : 2, explosion : 1, Behemoth : 1, PARIS : 1, Adjusts : 1, Illustration : 1, hall : 1, explore : 1, Contact : 1, slaughter : 1, groups : 1, Advertisers : 1, Briefing : 1, path : 1, along : 1, Times : 12, My : 3, search : 2, ArtsBeat : 1, Reads : 1, GlutenFree : 1, Bullies : 1, Cries : 1, Story’ : 1, action : 1, military : 1, residents : 1, navigation : 1, Stravinsky : 1, emerge : 1, Style : 6, Group : 1, campaign : 1, Readers : 5, Top : 1, Multimedia : 2, Three : 4, Eyes’ : 1, Contributing : 1, Enough : 4, Book : 1, Health : 5, names : 1, Opinion : 8, Kurds : 3, Dispute : 2, Europe : 2, Sanders : 1, Draw : 1, from : 2, Explorer : 2, would : 1, attackers : 1, Dies : 3, Deaton : 1, Cities’ : 1, next : 1, Driven : 1, Matters : 1, Moment : 2, Fell : 1, Lives : 1, passport : 1, Media : 2, Russian : 1, ‘Into : 1, tell : 1, Along : 1, underprivileged : 1, October : 1, erode : 1, Mom : 1, under : 1, Feast : 1, Vacation : 1, O’Malley : 1, Aspirations : 1, American : 1, downing : 1, Mass : 2, Editorial : 5, 92 : 1, adequate : 1, 97 : 1, must : 1, migrants : 1, Followed : 1, timesvideo : 1, LeftBank : 1, cap : 1, Pacific : 1, Professors : 2, SelfDefense : 1, Video : 6, View : 3, Our : 3, Your : 4, Out : 3, Poem : 1, violence : 1, Police : 1, do : 2, 554 : 1, Drivers : 1, ‘Secret : 1, one : 2, purposes : 1, Chimps : 1, DAVID : 1, 1980s : 1, Brian : 1, 2nd : 1, Bruni : 4, US : 4, Digital : 3, Cause : 1, information : 1, needs : 1, united : 1, Terms : 2, Issue : 1, ‘Letters : 1, Killing : 3, Unending : 1, how : 2, Meaning : 1, Saks : 1, 120000 : 1, SixTerm : 1, Weekend : 2, Why : 1, A : 10, Second : 2, Television : 2, Listings : 2, plans : 1, Migrant : 1, may : 1, Des : 1, earlier : 1, ANDREW : 1, Foreign : 1, Matter : 1, Martin : 1, president : 1, law : 1, Corporate : 2, response : 1, Obama’s : 1, purchase : 1, All : 3, Letters : 3, Series : 2, scatological : 1, Player : 1, chief : 1, assailant : 1, truck : 1, Bader : 2, Politics : 4, Reflect : 1, Sexual : 2, Bolster : 1, longer : 1, What : 1, Ginsburg : 3, help : 1, ‘By : 1, over : 1, Breaking : 1, Minnesota : 1, nbsp : 1, Toll : 1, Beirut : 1, ‘Men : 1, before : 1, KATRIN : 1, style : 1, Full : 1, police : 1, Rivals : 3, continued : 1, Brooks : 1, Cruz’s : 3, window : 1, stances : 1, GORDON : 1, MARTIN : 1, policy : 1, Mother’s : 1, Conservation : 2, soccer : 1, might : 1, Him : 1, fines : 1, SCHWIRTZ : 1, Evolution : 1, Bar : 1, Mobile : 2, Car : 2, L : 1, Choices : 1, 9 : 1, Can : 2, Social : 2, Ban : 1, Venus : 1, now : 1, day : 1, Respond : 3, EmailedMost : 1, opera : 1, Skip : 2, attacks : 3, events : 1, Depiction : 2, Indicates : 1, ATTACK : 1, Replica : 1, Gary : 1, Heels : 1, Check : 1, Arts : 8, Global : 1, From : 9, Retailer : 1, ‘American : 1, candidates’ : 1, ALISSA : 1, Steinem : 3, Sports : 5, ATSV : 1, Ajhar : 1, 89 : 1, Build : 1, Widens : 2, Routine : 1, Douthat : 1, Threaten : 1, Grips : 2, Save : 3, out : 1, Concert : 1, Wary : 1, Season : 1, ‘Wonderland’ : 1, 352 : 1, your : 2, content : 1, include : 1, War : 3, longtime : 1, emerged : 1, Cook : 1, get : 2, supports : 1, Tragedy : 1, Grave : 1, Stage : 2, Protect : 1, after : 1, Word : 2, Rights : 1, This : 2, Work : 1, Metal : 1, story : 2, free : 1, Drama : 1, struggle : 1, Corrections : 1, Meet : 2, Options : 1, Clinton : 5, Contributors : 1, Players : 1, Topics : 1, Sickness : 1, 8YearOld : 3, keep : 1, Universities : 1, Suicide : 1, Polite : 1, Copyright : 1, revenue : 1, Review : 13, coming : 2, Please : 2, Asia : 1, Fight : 2, Attackers : 1, Going : 1, Rates : 1, Fear : 2, Goes : 2, Syria : 1, SAYS : 1, Hollywood : 2, Speaks : 1, city : 1, Tests : 1, North : 2, Gains : 1, jet : 1, Eastern : 1, Kristof : 1, Symbol : 1, WORK : 1, Volkswagen : 1, Disrupted : 1, 2 : 2, tragic : 1, rates : 1, Iraq : 1, Response : 2, bloodshed : 1, Trophy : 1, Search : 4, B : 1, Neck : 1, Stampede : 1, Exploitation : 3, TearStreaked : 1, part : 1, Ireland : 1, Knocked : 1, Problem : 1, copy : 1, grace : 1, Road : 1, 10 : 2, Code : 1, 15 : 1, Cancer : 1, 16 : 1, Puzzle : 2, Only : 1, Cyber : 1, Sex : 1, Buyers Family : 1, Edition : 1, Region : 1, Sea : 1, were : 1, Raises : 2, Slowly : 1, Appetite : 1, providing : 1, Chance’ : 1, browser : 1, 2015Today’s : 1, Veteran : 1, fourbedroom : 1, raw : 1, Writers : 1, Inquiry : 1, America’ : 1, have : 1, need : 1, Transgender : 1, Soccer : 1, SHEEHAN : 1, Do : 2, East : 2, Fleeting : 1, Women’s : 1, Ukrainian : 1, Food : 6, Confusion : 1, After : 7, Thanksgiving : 8, Famous : 1, without : 1, ‘ACT : 1, take : 1, They : 1, Science : 3, objective : 1, With : 6, Hall : 1, Lloyd : 1, Worldwide : 1, Myself : 1, sure : 1, Episode : 1, Getting : 3, Attacks : 7, Blogs : 1, who : 2, Anybody : 1, Reports : 1, said : 2, sponsored : 1, Resigning : 1, remarks : 1, Alabama : 3, LIAM : 1, Side : 1, Responses : 2, Lands : 3, Account : 2, scrutinized : 1, flow : 1, Manners : 1, High : 3, Subscribe : 3, Single : 1, R : 1, Export : 1, Election : 2, Father’s : 2, Strip : 1, Sea’ : 1, Insurance : 2, Saturday : 1, came : 1, Rise : 1, bomb : 1, Paris : 20, text : 1, ET : 3, SCHMITT : 1, Suspects : 2, Comments : 1, Role : 2, Hill : 1, Innovation : 2, Smile : 1, Anne : 1, Has : 1, Public : 2, Affordable : 1, access : 1, We : 1, Democratic : 4, RICHARD : 1, WAR’ : 1, Joy : 1, Photography : 2, Republicans : 1, 11115 : 1, French : 2, Todayrsquos : 2, only : 1, Craft : 1, Diary : 1, York : 8, Solar : 1, Services : 1, Hamilton : 1, blinds : 1, he : 1, Few : 2, Legend : 1, Carnage : 1, centrally : 1, Homes : 4, CHOZICK : 1, Roper : 1, hit : 1, Applause : 1, Expanded : 1, Wife : 2, Turns : 1, Favorite : 1, FretFree : 1, Leave : 1, Magazine : 7, Set : 1, 129 : 1, Outcry : 1, Muscle : 1, Having : 1, Saying : 1, Protests : 1, Help : 1, countries : 1, New : 10, Over : 2, Move : 1, Inflicting : 2, jokes : 1, ViewedRecommended : 1, Anger : 1, Broadway : 1, GALANES : 1, Education : 4, Guides : 2, generations : 1, Badlands’ : 1, respond : 1, Alice’s : 1, decides : 1, concert : 1, For : 5, criticized : 1, Diamonds : 1, BENNHOLD : 1, France : 3, Dayton : 1, officials : 2, result : 1, Profit : 1, Frank’s : 1, Ebola : 1, Derails : 1, Ansari : 2, Palatable : 2, Good : 1, Gift : 1, Fights : 1, Woozy : 1, Towers : 1, flyfishing : 1, Horror : 2, laureate : 1, BY : 1, Water : 2, 3 : 1, Harvard : 2, Adele : 1, Bookshelf : 1, Republican : 2, CeaseFire : 1, Moines : 1, Kitchen : 1, DesignCentered : 1, Véra’ : 1, Path : 1, Settings : 1, Could : 1, Borrowing : 1, Identified : 2, weren’t : 1, City : 1, His : 2, OpEd : 3, 20 : 1, Advertise : 1, Extinction : 1, Give : 1, Dance : 1, many : 1, Louis : 1, Hard : 1, Focus : 1, foreign : 1, Hours : 1, Camryn : 1, Race : 2, Design : 1, planned : 1, Lawyer : 1, faces : 1, Dawn : 1, React : 1, Syrian : 1, Campus : 2, among : 1, Death : 2, Log : 1, Her : 2, Travel : 4, Mr : 1, Nobel : 1, Note : 1, unfolded : 1, Join : 1, Samples : 1, Love : 2, trust : 1, Events : 3, Gives : 1, turkey : 1, Urge : 2, Play : 2, Pain : 1, videos : 1, Beauty : 1, Get : 1, Students : 1, KIRKPATRICK : 1, Hollande : 2, three : 2, But : 1, Cheaper : 1, skyhigh : 1, Most : 1, Brooklyn : 2, Train : 1, California : 3, Plan : 2, stadium : 1, Aziz : 2, ‘Sanctuary : 1, Bittman : 2, Insider : 3, Women : 1, Neediest : 1, Ménage : 1, families : 1, great : 1, 2015 : 1, Points : 1, Wordplay : 1, World : 4, towns : 1, Bites : 1, Round : 1, Upper : 1, 2016 : 2, Todays : 3, look : 1, T : 4, Journeys : 1, Manage : 1, Sales : 1, By : 13, near : 1, Accused : 3, College : 1, NOSSITER : 1, Chip : 1, Market : 2, MORE : 1, upgrade : 1, rap : 1, Rodham : 1, Menu : 1, sticker : 1, Tennis : 2, Tip : 1, them : 1, TEAMS : 1, Tim : 1, RUBIN : 1, Candidates : 2, Useless : 2, LEARN : 1, Victims : 1, Eagles : 1, Tell : 1, Hope : 1, D : 1, Policing : 1, Merchandising : 1, threatens : 1, began : 1, Socially : 1, defiant : 1, NYTimescom : 2, Manheim’s : 1, Many : 2, Oxford : 1, JONATHAN : 1, STACK : 1, Live’ : 1, difficult : 1, BREEDEN : 1, Room : 1, Poet’s : 1, Editorials : 1, I : 2, Potatoes : 1, Clear : 1, Escape : 1, hand : 1, Movies : 2, We’ve : 1, Be : 3, Home : 5, Jolie : 1, Order : 2, Gloria : 2, Bridge’ : 1, Classifieds : 1, Patron : 1, Challenged : 1, Technology : 1, Is : 6, Wines : 1, Yazidis : 1, It : 1, Julia : 1, Offenses : 1, May : 1, Rate : 1, Economic : 1, Rent : 1, Have : 2, In : 5, Table : 2, Tools : 1, know : 1, Living : 1, spurred : 1, Loading : 2, Upheaval : 1, Using : 1, Service : 1, moments : 1, captures : 1, Mother : 2, rest : 1, Access : 1, front : 1, Sunday : 10, properties : 2, Internet : 2, Include : 1, perilous : 1, captured : 1, previous : 2, Bistro : 1, unique : 1, Jobs : 1, Band : 1, Company : 1, Privacy : 1, Freshened : 1, discuss : 1, Applications : 1, nbspComments : 4, input : 1, Support : 1, Kirp : 1, Delivery : 1, On : 3, NEIL : 1, Faster : 1, Thread : 1, Restaurant : 1, James : 1, Taking : 1, To : 4, Roberts : 1, Ask : 1, Investigate : 1, Fashion : 4, traffic : 1, Mascara : 1, Retracing : 1, Missouri : 3, PHILIP : 1, IBM’s : 3, dreams : 1, Wine : 1, Law : 2, Art : 2, OF : 2, Cohen : 3, News : 5, Pie : 1, Desserts : 1, ‘Fall : 1, Durham : 1, Rising : 1, Are : 4, Columnists : 1, Gunmen : 1, Music : 3, 中文 : 1, accuracy : 1, Species : 1, Witness : 1, Too : 2, Newsletters : 1, Way : 1, Articles : 2, Fears : 1, Mark : 2, Crossword : 4, Much : 1, Editor : 2, Clinton’s : 2, Mars : 1, Terror : 8, International : 2, Student : 2, Email : 1, Injured : 1, Fringes : 1, Driverless : 1, Frank : 3, AMC : 1, Men : 1, recorded : 1, Say : 1, People : 1, Gifts : 1, everything : 2, does : 1, Facebook : 1, FactChecking : 1, Cooking : 1, collaboration : 1, Nabokov : 2, Simpler : 1, Cellphone : 1, Adviser : 1, Survivor’s : 1, Inside : 1, night : 1, MICHAEL : 2, Up : 1, Us : 2, David : 2, Technophoria : 2, Vietnam : 2, Place : 1, Druckerman : 1, AURELIEN : 1, Lanes : 1, AN : 1, Think : 1, Attack : 4, First : 1, ‘A : 1, Mired : 1, Bouquet : 1, Dyson : 1, deductibles : 1, graduation : 1, Valentine : 1, undocumented : 1, dinner : 1, Paper : 1, Distant : 3, User : 1, Games : 1, Robert : 2, Wintry : 1, Books : 3, Rape : 2, Really : 1, Voyage : 1, Story : 3, own : 1, Bears : 1, Make : 6, Alerts : 1, Two : 2, Unhappy : 1, Immigration : 1, Their : 3, Acting : 2, François : 1, Draft : 1, raises : 1, Revolution : 3, Survive : 2, Ruth : 2, Sauce : 1, The : 33, Store : 1, Week : 1, MICHELLE : 1, NJ : 1, Extended : 2, ISIS : 11, prepare : 1, Automobiles : 2, friends : 1, Hillary : 4, long : 1, Page : 1, NY : 4, Obituaries : 2, Channeling : 1, Coverage : 1, forward : 1, November : 1, Bernie : 1, ‘Nabokov : 1, elsewhere : 2, HIGGINS : 2, PEAR : 1, J : 1, Well : 4, Known : 1, Google : 1, Stopped : 1, Killed : 2, Roast : 1, Defeat : 3, Small : 1, Opinionator : 1, Austin : 1, Guide : 3, Interactive : 1, traveled : 1, portions : 1, Estate : 4, Sinjar : 1, Ted : 3, us : 2, Song’ : 1, County : 1, Investigation : 1, 720 : 1, Close : 1, Aggressive : 2, Care : 1, Crisis : 1, » : 2, passenger : 1, his : 1, Weddings : 1, culinary : 1, ‘CoAuthor’ : 1, untidy : 1, taste : 1, Some : 1, Writes : 2, Free : 2, Crust : 1, pie : 1, Merrimack : 1, an : 3, twist : 1, How : 9, Hot : 1, Century : 2, MILAN : 1, Last : 2, PaperVideo : 1, Upshot : 1, dietary : 1, Squares : 1, identities : 1, Manhattan : 1, Pinkel : 1, Real : 4, Map : 1, Toddler : 3, Fate : 1, raquo : 34, TV : 1, ROBERT : 1, when : 2, Possible : 1, end : 1, Islamic : 2, Gimbel’s : 1, other : 1, 5 : 4, sick : 1, digital : 1, Improving : 1, Missouri8217s : 1, you : 4, Carolina : 2, Pages : 1, Case : 2, Kurdish : 1, Vladimir : 2, Shift : 4, GuiltFree : 1, Hunt : 1, AM : 3, Poker : 1, Steward : 1, recent : 1, Martial : 1, coverage : 1, Act : 1, included : 1, Congressman : 1, St : 1, Documentary : 2, Download : 1, Scene : 1, admissions : 1, Coach : 1, fighter : 1, Ad : 1, Myanmar : 1, victims : 1, Win : 1, Strategy : 4, Modern : 1, Site : 3, Its : 1, Critic : 1, Rituals : 1, weights : 1, At : 2, Village : 1, Roger : 3, Refined : 1, }\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('nytimes.com.frequency', 'w')\n",
    "pickle.dump(nytimes_dic, f)\n",
    "f.close()\n",
    "\n",
    "#저장된 파일 읽어 확인하기\n",
    "f = open('nytimes.com.frequency')\n",
    "loadtxt = pickle.load(f)\n",
    "print '{',\n",
    "for x in loadtxt :\n",
    "    print \"%s : %d,\" % (x, loadtxt[x]), \n",
    "print '}'\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) 최소 5개 이상의 영어 웹 사이트에 대한 HTML 소스 파일과 단어 출현빈도 파일을 저장하시오.\n",
    "즉, 총 10개의 파일을 동일한 폴더에 생성하시오.\n",
    "[주의] 영어 웹사이트 URL로만 5개 이상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "punc = string.punctuation\n",
    "\n",
    "source1 = urllib2.urlopen(\"http://yukoncollege.yk.ca/\").read()\n",
    "real_source1 = source1\n",
    "\n",
    "for i in range(0, source1.count('<script')) :\n",
    "    if source1.find('<script') != -1 :\n",
    "        source1=source1.replace(source1[source1.find('<script'):source1.find('</script>')+9],\"\")\n",
    "        \n",
    "for i in range(0, source1.count('<style')) :\n",
    "    if source1.find('<style') != -1 :\n",
    "        source1=source1.replace(source1[source1.find('<style'):source1.find('</style>')+8],\"\")\n",
    "\n",
    "for i in range(0, source1.count('<!--')):\n",
    "    if source1.find(\"<!--\") != -1:\n",
    "        source1 = source1.replace(source1[source1.find(\"<!--\"):source1.find(\"-->\")+3:],\"\")\n",
    "        \n",
    "for i in range(0,source1.count(\"<\")):\n",
    "    if source1.find(\"<\") != -1:\n",
    "        source1 = source1.replace(source1[source1.find(\"<\"):source1.find(\">\")+1:],\"\")\n",
    "        \n",
    "words1 = source1.split()\n",
    "\n",
    "delPuncList1 = []\n",
    "puncStr1 = ''\n",
    "\n",
    "# punctuation(구두문자) 제거\n",
    "\n",
    "for x in words1:\n",
    "    puncStr1 = ''\n",
    "    for y in x:\n",
    "        if y in punc :\n",
    "            puncStr1 = puncStr1 + ''\n",
    "        else :\n",
    "            puncStr1 = puncStr1 + y\n",
    "    delPuncList1.append(puncStr1)\n",
    "    \n",
    "# 구두문자 제거 후 출력\n",
    "#for x in delPuncList1 :\n",
    "#    print x\n",
    "\n",
    "NSpaceList1 = []\n",
    "\n",
    "#공백문자 제거\n",
    "for x in delPuncList1 :\n",
    "    if x in string.whitespace :\n",
    "        pass\n",
    "    else :\n",
    "        NSpaceList1.append(x)\n",
    "\n",
    "#공백문자 제거 후 출력        \n",
    "#for x in NSpaceList1 :\n",
    "#   print x\n",
    "    \n",
    "#단어 빈도수 확인\n",
    "ykcollege_dic = {}\n",
    "\n",
    "for x in NSpaceList1 :\n",
    "    ykcollege_dic[x] = NSpaceList1.count(x)\n",
    "    \n",
    "stopWords = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', \n",
    "              'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']\n",
    "\n",
    "delStopWordList1 = []\n",
    "\n",
    "for word in NSpaceList1 :\n",
    "    if word in stopWords :\n",
    "        pass\n",
    "    else :\n",
    "        delStopWordList1.append(word)\n",
    "        \n",
    "#불용성 영단어 제거 후 단어 빈도수 확인\n",
    "ykcollege_dic = {}\n",
    "\n",
    "for x in delStopWordList1 :\n",
    "    ykcollege_dic[x] = delStopWordList1.count(x)\n",
    "    \n",
    "#html소스 저장        \n",
    "f = open('yukoncollege.yk.ca.html', 'w')\n",
    "f.write(real_source1)\n",
    "f.close()\n",
    "\n",
    "#단어 빈도수 저장\n",
    "f = open('yukoncollege.yk.ca.frequency', 'w')\n",
    "pickle.dump(ykcollege_dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ limited : 1, all : 1, Winter : 1, Social : 1, vary : 1, Research : 1, leads : 1, identify : 1, nbsp : 1, Innovation : 1, Test : 1, Robertson : 1, 15pm : 1, Oct : 2, issues : 1, staff : 1, Foundation : 1, 26 : 1, 27 : 1, 20 : 1, Carmacks : 1, Schedule : 1, THINGS : 1, 28 : 1, Award : 1, program : 2, Services : 2, News : 2, Nov : 1, Day : 4, Anxiety : 1, Last : 1, Programs : 1, Wins : 1, Thanksgiving : 1, indigenous : 1, Classes : 1, nearly : 1, fall : 1, during : 1, instructor : 1, dondashndashor : 1, closure : 1, term : 1, Art : 1, Links : 1, Kampen : 1, 1011 : 1, Centre : 1, 2799 : 1, COLLEGE : 1, team : 1, including : 1, Check : 1, ROOTS : 1, ABOUT : 1, right : 1, YMTA : 1, Term : 1, library : 1, INDIGENOUS : 1, intensity : 1, college : 1, Library : 5, 7th : 1, our : 1, 11th : 1, More : 1, 02 : 1, Myth : 1, 08 : 2, 09 : 1, research : 1, Ukjese : 1, Inuitndashndashas : 1, closed : 5, Magna : 1, international : 1, PO : 1, Box : 1, core : 1, Dates : 1, LOVE : 1, University : 1, Work : 1, Us : 2, graduates : 1, 18006610504 : 1, Contact : 1, Events : 1, become : 1, Directory : 1, news : 1, Registration : 1, First : 5, about : 1, September : 4, country : 1, 30 : 1, introduces : 1, quiet : 1, recognized : 1, Find : 1, Individual : 1, Questions : 1, Archive : 1, Calendar : 1, Scholarships : 1, whats : 1, Remembrance : 1, Aug : 2, Privacy : 1, feel : 1, Studying : 1, Fri : 1, 5K4 : 1, Little : 1, DEEP : 1, Writing : 2, Whitehorse : 1, Labour : 1, registration : 1, open : 1, your : 1, Careers : 1, yoursquoll : 1, van : 1, August : 2, Hub : 2, area : 1, BSW : 1, Salmon : 1, Y1A : 1, Awards : 1, Updates : 1, YUKON : 1, November : 3, Renovation : 1, TALK : 1, more : 1, October : 1, 2627 : 1, Strategically : 1, award : 1, Nations : 2, Courses : 1, If : 1, PDF : 1, selfdetermination : 1, copy : 1, Sept : 1, Important : 1, History : 1, 10 : 1, 13 : 1, 12 : 1, Office : 1, 2015 : 1, 19 : 1, 18 : 1, work : 1, up : 1, 867 : 1, YukonU : 1, preparation : 1, See : 1, College : 13, 500 : 1, learn : 1, Lorene : 1, providing : 1, PREP : 2, Information : 1, Thurs : 1, Reality : 1, Meacutetis : 1, Exam : 2, want : 1, International : 1, Policy : 1, Carta : 1, Presentation : 1, EXAM : 2, competency : 1, Begin : 1, 6688800 : 1, Nation : 2, Admissions : 1, TO : 1, Session : 1, 5 : 1, Student : 5, Fall : 1, you : 3, out : 1, Dr : 1, Posted : 7, About : 1, Handling : 1, may : 2, Launches : 1, Drive : 1, MyYC : 1, most : 1, YUKONCOLLEGEME : 1, PUBLIC : 1, services : 1, The : 3, weekend : 1, deadline : 1, View : 1, happening : 1, amp : 4, programs : 2, home : 1, It : 1, Community : 1, heating : 1, students : 1, plumbing : 1, Yukon : 10, usual : 1, }\n"
     ]
    }
   ],
   "source": [
    "f = open('yukoncollege.yk.ca.frequency')\n",
    "loadtxt = pickle.load(f)\n",
    "print '{',\n",
    "for x in loadtxt :\n",
    "    print \"%s : %d,\" % (x, loadtxt[x]), \n",
    "print '}'\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "punc = string.punctuation\n",
    "\n",
    "source2 = urllib2.urlopen(\"http://www.apple.com/\").read()\n",
    "real_source2 = source2\n",
    "\n",
    "for i in range(0, source2.count('<script')) :\n",
    "    if source2.find('<script') != -1 :\n",
    "        source2=source2.replace(source2[source2.find('<script'):source2.find('</script>')+9],\"\")\n",
    "        \n",
    "for i in range(0, source2.count('<style')) :\n",
    "    if source2.find('<style') != -1 :\n",
    "        source2=source2.replace(source2[source2.find('<style'):source2.find('</style>')+8],\"\")\n",
    "\n",
    "for i in range(0, source2.count('<!--')):\n",
    "    if source2.find(\"<!--\") != -1:\n",
    "        source2 = source2.replace(source2[source2.find(\"<!--\"):source2.find(\"-->\")+3:],\"\")\n",
    "        \n",
    "for i in range(0,source2.count(\"<\")):\n",
    "    if source2.find(\"<\") != -1:\n",
    "        source2 = source2.replace(source2[source2.find(\"<\"):source2.find(\">\")+1:],\"\")\n",
    "        \n",
    "words2 = source2.split()\n",
    "\n",
    "delPuncList2 = []\n",
    "puncStr2 = ''\n",
    "\n",
    "# punctuation(구두문자) 제거\n",
    "\n",
    "for x in words2:\n",
    "    puncStr2 = ''\n",
    "    for y in x:\n",
    "        if y in punc :\n",
    "            puncStr2 = puncStr2 + ''\n",
    "        else :\n",
    "            puncStr2 = puncStr2 + y\n",
    "    delPuncList2.append(puncStr2)\n",
    "    \n",
    "# 구두문자 제거 후 출력\n",
    "#for x in delPuncList2 :\n",
    "#    print x\n",
    "\n",
    "NSpaceList2 = []\n",
    "\n",
    "#공백문자 제거\n",
    "for x in delPuncList2 :\n",
    "    if x in string.whitespace :\n",
    "        pass\n",
    "    else :\n",
    "        NSpaceList2.append(x)\n",
    "\n",
    "#공백문자 제거 후 출력        \n",
    "#for x in NSpaceList2 :\n",
    "#    print x\n",
    "    \n",
    "#단어 빈도수 확인\n",
    "apple_dic = {}\n",
    "\n",
    "for x in NSpaceList2 :\n",
    "    apple_dic[x] = NSpaceList2.count(x)\n",
    "    \n",
    "stopWords = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', \n",
    "              'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']\n",
    "\n",
    "delStopWordList2 = []\n",
    "\n",
    "for word in NSpaceList2 :\n",
    "    if word in stopWords :\n",
    "        pass\n",
    "    else :\n",
    "        delStopWordList2.append(word)\n",
    "        \n",
    "#불용성 영단어 제거 후 단어 빈도수 확인\n",
    "apple_dic = {}\n",
    "\n",
    "for x in delStopWordList2 :\n",
    "    apple_dic[x] = delStopWordList2.count(x)\n",
    "\n",
    "#html소스 저장        \n",
    "f = open('www.apple.com.html', 'w')\n",
    "f.write(real_source2)\n",
    "f.close()\n",
    "\n",
    "#단어 빈도수 저장\n",
    "f = open('www.apple.com.frequency', 'w')\n",
    "pickle.dump(apple_dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ shop : 1, United : 1, changed is everything : 1, Opportunities : 1, iTunes : 1, Supplier : 1, find : 1, Introducing : 1, Reuse : 1, Business : 5, Watch : 6, only : 1, 4 : 1, 2015 : 1, News : 1, Now : 1, Account : 2, Bar : 1, Programs : 1, Youth : 1, Bag : 2, Responsibility : 1, iPhone : 4, Cards : 1, Shop : 3, Help : 1, gift : 1, Pro : 2, Accessories : 1, Learning : 1, Music : 2, Education : 3, Find : 2, iPad : 6, From : 1, For : 3, colossal : 1, Legal : 1, Accessibility : 1, More : 1, Pencil : 1, Shopping : 3, Gift : 1, ways : 1, Retina : 1, Job : 1, Info : 2, iCloudcom : 1, Light : 1, Contact : 1, wear : 1, Inclusion : 1, App : 1, Recycling : 1, thing : 1, Mighty : 1, that’s : 1, Thin : 1, Use : 1, love : 1, Copyright : 1, Privacy : 2, Support : 1, Visit : 1, one : 1, Environment : 1, Genius : 1, Refurbished : 1, Epic : 1, Events : 1, Store : 5, Status : 1, Diversity : 1, ID : 1, call : 1, Press : 1, 1800MYAPPLE : 1, come many : 1, Financing : 1, Footer : 1, 6s : 1, Learn : 4, Small : 1, iPod : 1, is here : 1, television : 1, rights : 1, Manage : 1, Sales : 1, iMac : 1, future : 1, College : 1, applecom : 1, Close : 8, more : 3, Open : 8, Your : 2, Inc : 1, mini : 1, reserved : 1, Menu : 16, Search : 1, an : 1, To : 1, Hot : 1, Policy : 1, film : 3, Map : 1, Terms : 1, TV : 3, Mac : 3, Investors : 1, About : 1, Refunds : 1, © : 1, gifts : 1, Values : 1, The : 2, Order : 1, All : 1, ginormous : 1, Apple : 18, reseller : 1, Workshops : 1, Site : 1, States : 1, }\n"
     ]
    }
   ],
   "source": [
    "f = open('www.apple.com.frequency')\n",
    "loadtxt = pickle.load(f)\n",
    "print '{',\n",
    "for x in loadtxt :\n",
    "    print \"%s : %d,\" % (x, loadtxt[x]), \n",
    "print '}'\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "punc = string.punctuation\n",
    "\n",
    "source3 = urllib2.urlopen(\"http://www.yvr.ca/\").read()\n",
    "real_source3 = source3\n",
    "\n",
    "for i in range(0, source3.count('<script')) :\n",
    "    if source3.find('<script') != -1 :\n",
    "        source3=source3.replace(source3[source3.find('<script'):source3.find('</script>')+9],\"\")\n",
    "        \n",
    "for i in range(0, source3.count('<style')) :\n",
    "    if source3.find('<style') != -1 :\n",
    "        source3=source3.replace(source3[source3.find('<style'):source3.find('</style>')+8],\"\")\n",
    "\n",
    "for i in range(0, source3.count('<!--')):\n",
    "    if source3.find(\"<!--\") != -1:\n",
    "        source3 = source3.replace(source3[source3.find(\"<!--\"):source3.find(\"-->\")+3:],\"\")\n",
    "        \n",
    "for i in range(0,source3.count(\"<\")):\n",
    "    if source3.find(\"<\") != -1:\n",
    "        source3 = source3.replace(source3[source3.find(\"<\"):source3.find(\">\")+1:],\"\")\n",
    "        \n",
    "words3 = source3.split()\n",
    "\n",
    "delPuncList3 = []\n",
    "puncStr3 = ''\n",
    "\n",
    "# punctuation(구두문자) 제거\n",
    "\n",
    "for x in words3:\n",
    "    puncStr3 = ''\n",
    "    for y in x:\n",
    "        if y in punc :\n",
    "            puncStr3 = puncStr3 + ''\n",
    "        else :\n",
    "            puncStr3 = puncStr3 + y\n",
    "    delPuncList3.append(puncStr3)\n",
    "    \n",
    "# 구두문자 제거 후 출력\n",
    "#for x in delPuncList3 :\n",
    "#    print x\n",
    "\n",
    "NSpaceList3 = []\n",
    "\n",
    "#공백문자 제거\n",
    "for x in delPuncList3 :\n",
    "    if x in string.whitespace :\n",
    "        pass\n",
    "    else :\n",
    "        NSpaceList3.append(x)\n",
    "\n",
    "#공백문자 제거 후 출력        \n",
    "#for x in NSpaceList3 :\n",
    "#    print x\n",
    "    \n",
    "#단어 빈도수 확인\n",
    "yvr_dic = {}\n",
    "\n",
    "for x in NSpaceList3 :\n",
    "    yvr_dic[x] = NSpaceList3.count(x)\n",
    "    \n",
    "stopWords = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', \n",
    "              'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']\n",
    "\n",
    "delStopWordList3 = []\n",
    "\n",
    "for word in NSpaceList3 :\n",
    "    if word in stopWords :\n",
    "        pass\n",
    "    else :\n",
    "        delStopWordList3.append(word)\n",
    "\n",
    "#불용성 영단어 제거 후 단어 빈도수 확인\n",
    "yvr_dic = {}\n",
    "\n",
    "for x in delStopWordList3 :\n",
    "    yvr_dic[x] = delStopWordList3.count(x)\n",
    "\n",
    "#html소스 저장        \n",
    "f = open('www.yvr.ca.html', 'w')\n",
    "f.write(real_source3)\n",
    "f.close()\n",
    "\n",
    "#단어 빈도수 저장\n",
    "f = open('www.yvr.ca.frequency', 'w')\n",
    "pickle.dump(yvr_dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ Canada : 4, all : 3, enjoyable : 1, Dining : 3, manages : 1, Helijet : 1, Scheduled : 1, Designer : 1, Columbia : 2, Business : 1, eligible : 1, Award : 1, McArthurGlen : 1, Visitors : 1, program : 2, helps : 1, Schedules : 1, Purolator : 1, Now : 1, Prize : 1, Canadian : 2, continues : 1, Sale : 1, updates : 1, facilities : 1, issue : 1, standards : 1, Concierge : 1, Innovative : 2, Go : 2, inspection : 1, expanded : 1, Stats : 1, EVA : 1, Long : 1, design : 1, cargo : 1, what : 1, Print : 1, 0200 : 4, new : 1, America : 1, Transat : 1, Work : 1, Fees : 1, water : 1, Contact : 1, Ltd : 3, wait : 1, passengers : 2, items : 1, Your : 1, CBP : 1, 4950 : 1, changes : 1, Mountain : 1, Group : 1, Limousines : 1, Privacy : 1, Top : 1, Visit : 3, Seaplanes : 1, visible : 1, Book : 1, Safety : 1, select : 1, Status : 1, environment : 1, from : 3, Notifications : 1, remains : 1, 0500 : 4, Express : 2, flights : 2, process : 2, automate : 1, Media : 2, more : 8, October : 1, Valet : 1, Banking : 1, American : 1, Beverage : 1, Time : 2, Routes : 1, Found : 2, Browser : 1, Edelweiss : 1, Family : 1, rights : 1, Text : 1, 0800 : 4, Pacific : 2, Improvements : 1, Our : 2, my : 1, could : 1, Inc : 2, reserved : 1, Northern : 1, Federal : 1, Corporation : 1, Feature : 1, WestJet : 1, Sign : 2, maps : 1, airline : 1, A : 1, CheckIn : 1, British : 3, customs : 1, routes : 1, designed : 1, Swiss : 1, Disclaimer : 1, All : 3, 2015160Vancouver : 1, Community : 2, baggage : 1, Litres : 1, Ship : 1, typical : 1, Enerjet : 1, Cycling : 1, help : 1, office : 1, move : 1, YVR’s : 1, including : 1, nbsp : 1, Forces : 1, its : 1, 20 : 1, Exchange : 1, 29 : 1, 2015 : 4, World : 1, main : 1, easier : 1, 2013 : 1, 2012 : 1, Mobile : 1, Car : 1, Suppliers : 1, arriving : 2, now : 2, Control : 3, airports : 2, Skip : 1, times : 1, Saltspring : 1, Authority : 5, Flightcraft : 1, APC : 2, Destinations : 1, Zealand : 1, From : 2, Distance : 1, 700 : 1, related : 1, 89 : 1, Passport : 3, eYVRthing : 1, Warehouse : 1, our : 4, Save : 1, Noise : 1, Promo : 1, content : 2, Construction : 1, China : 4, Outlet : 1, Report : 1, Tariff : 1, EN : 1, Places : 1, This : 1, Thunderbird : 1, Plaza : 1, 0100 : 4, Arrivals : 1, Architecture : 1, Transportation : 1, Security : 1, Photo : 1, National : 1, Eastern : 1, Concession : 1, Harbour : 1, keep : 1, Cathay : 1, Currency : 1, Facts : 1, retail : 1, 1000 : 4, Sedans : 1, Copyright : 1, Please : 1, number : 1, Maps : 1, improvements : 1, leasing : 1, electronic : 1, Careers : 1, North : 2, Centre : 2, Coast : 1, Environmental : 1, Courtesy : 1, Automated : 2, View : 5, recovered : 1, Search : 1, Qantas : 1, Delta : 1, part : 1, Taxis : 1, than : 3, Road : 1, History : 1, 10 : 1, Code : 1, 14 : 1, Conferences : 1, KD : 1, Latest : 3, Sea : 2, browser : 2, Information : 7, 2014 : 1, Inquiry : 1, have : 2, need : 1, Mail : 4, border : 1, any : 1, Development : 1, 1In : 1, Flight : 5, Parcel : 1, Airways : 4, Food : 1, WiFi : 1, Cargojet : 1, With : 1, Gallery : 1, Français中文 : 1, Getting : 1, Advertising : 1, Horizon : 1, services : 1, The : 1, gallery : 1, Childrens : 1, Sunwing : 1, clear : 1, Philippine : 1, Want : 1, 0700 : 4, departing : 2, Loading : 1, Public : 1, Premium : 1, Exit : 1, Update : 1, Free : 2, operational : 2, terminal : 1, Sustainability : 1, only : 1, Leadership : 1, Services : 6, photography : 1, Annual : 1, archivesnbsp : 1, Passenger : 1, activity : 1, through : 1, Guides : 1, Tofino : 1, available : 1, art : 1, Driving : 1, Area : 1, nbspFree : 1, Alaska : 1, France : 2, Bicycles : 1, Skytrax : 1, ArrivalsDepartures : 1, Shopping : 5, Islandnbsp : 1, sites : 1, between : 1, Postal : 1, across : 1, PM : 26, Info : 1, we : 2, Central : 1, Parking : 2, aquarium : 1, Condor : 1, installation : 1, Tours : 1, Coastal : 1, Yes : 1, Travel : 2, congestion : 1, Skyservice : 1, Lounge : 2, Holiday : 1, Get : 2, annbspAutomated : 1, create : 1, informed : 1, airlines : 1, cent : 1, strategy : 1, 1205 : 2, Protection : 1, Card : 1, Care : 1, graphical : 1, flight : 2, 1200 : 2, 169 : 1, Learn : 5, Accountability : 1, 160 : 1, Terminal : 1, Manage : 1, Culture : 1, while : 1, 1100 : 4, owns : 1, Follow : 1, shops : 1, Commuting : 1, launched : 2, Hotels : 1, City : 2, Hawkair : 1, Better : 1, make : 2, airport : 4, Island : 2, RSS : 1, Chapel : 1, development : 1, 0400 : 4, About : 2, Charges : 1, Lines : 1, Airport : 14, supports : 1, Shuttles : 1, Buses : 1, Border : 1, Sichuan : 1, costs : 1, In : 2, clearance : 1, latest : 2, Helicopters : 1, YVRFacts : 1, United : 2, Service : 2, photo : 1, Forms : 1, Internet : 1, web : 1, BORDERXPRESS™ : 2, YouTube : 1, Assistance : 1, 0300 : 4, Building : 1, 114Thousand : 1, YVR : 19, 1155 : 2, Wins : 1, Air : 27, amp : 15, Art : 1, Newsletters : 1, Share : 2, Accessibility : 2, 10year : 1, 0600 : 4, London : 1, YVRs : 1, Health : 2, Fine : 1, accessible : 1, jetSet : 1, Management : 2, West : 1, Nippon : 1, DHL : 1, International : 5, newsletter : 1, Email : 1, throughout : 2, notification : 1, per : 1, Customs : 2, Planning : 1, Facebook : 1, Arriving : 1, booking : 1, Us : 3, 0900 : 4, become : 1, snapped : 1, about : 6, US : 2, BCAA : 1, journey : 1, ensure : 1, Solutions : 2, Japan : 1, Upgrade : 1, Southern : 1, Immigration : 1, Environment : 1, device : 1, Flights : 3, Charters : 1, Seair : 1, Navigating : 1, Korean : 1, reducing : 1, Meeting : 1, your : 2, awardwinning : 1, NA : 1, much : 1, Directions : 1, November : 2, Passengers : 1, driver : 1, construction : 1, Healthcare : 1, Highland : 1, Distinguished : 1, partially : 1, Duty : 2, Leasing : 1, Flugdienst : 1, Twitter : 2, up : 3, us : 1, economic : 1, Cruise : 1, Cargo : 2, Kelowna : 1, inclusive : 1, Personal : 1, Airlines : 14, an : 1, Blog : 2, To : 3, Land : 1, Vancouver : 7, New : 1, Homepage : 1, archive : 1, Map : 1, variety : 1, Quote : 1, Lufthansa : 1, warehouse : 1, you : 4, Icelandair : 1, Lost : 2, favourite : 1, KLM : 1, AM : 24, Future : 1, Airline : 1, Entry : 1, Rentals : 1, South : 2, land : 1, faster : 2, Departing : 1, Site : 2, 2001 : 1, At : 1, Gateway : 1, }\n"
     ]
    }
   ],
   "source": [
    "f = open('www.yvr.ca.frequency')\n",
    "loadtxt = pickle.load(f)\n",
    "print '{',\n",
    "for x in loadtxt :\n",
    "    print \"%s : %d,\" % (x, loadtxt[x]), \n",
    "print '}'\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "punc = string.punctuation\n",
    "\n",
    "source4 = urllib2.urlopen(\"http://www.seattle.gov/\").read()\n",
    "real_source4 = source4\n",
    "\n",
    "for i in range(0, source4.count('<script')) :\n",
    "    if source4.find('<script') != -1 :\n",
    "        source4=source4.replace(source4[source4.find('<script'):source4.find('</script>')+9],\"\")\n",
    "        \n",
    "for i in range(0, source4.count('<style')) :\n",
    "    if source4.find('<style') != -1 :\n",
    "        source4=source4.replace(source4[source4.find('<style'):source4.find('</style>')+8],\"\")\n",
    "\n",
    "for i in range(0, source4.count('<!--')):\n",
    "    if source4.find(\"<!--\") != -1:\n",
    "        source4 = source4.replace(source4[source4.find(\"<!--\"):source4.find(\"-->\")+3:],\"\")\n",
    "        \n",
    "for i in range(0,source4.count(\"<\")):\n",
    "    if source4.find(\"<\") != -1:\n",
    "        source4 = source4.replace(source4[source4.find(\"<\"):source4.find(\">\")+1:],\"\")\n",
    "        \n",
    "words4 = source4.split()\n",
    "\n",
    "delPuncList4 = []\n",
    "puncStr4 = ''\n",
    "\n",
    "# punctuation(구두문자) 제거\n",
    "\n",
    "for x in words4:\n",
    "    puncStr4 = ''\n",
    "    for y in x:\n",
    "        if y in punc :\n",
    "            puncStr4 = puncStr4 + ''\n",
    "        else :\n",
    "            puncStr4 = puncStr4 + y\n",
    "    delPuncList4.append(puncStr4)\n",
    "    \n",
    "# 구두문자 제거 후 출력\n",
    "#for x in delPuncList4 :\n",
    "#    print x\n",
    "\n",
    "NSpaceList4 = []\n",
    "\n",
    "#공백문자 제거\n",
    "for x in delPuncList4 :\n",
    "    if x in string.whitespace :\n",
    "        pass\n",
    "    else :\n",
    "        NSpaceList4.append(x)\n",
    "\n",
    "#공백문자 제거 후 출력        \n",
    "#for x in NSpaceList4 :\n",
    "#    print x\n",
    "    \n",
    "#단어 빈도수 확인\n",
    "seattle_dic = {}\n",
    "\n",
    "for x in NSpaceList4 :\n",
    "    seattle_dic[x] = NSpaceList4.count(x)\n",
    "    \n",
    "stopWords = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', \n",
    "              'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']\n",
    "\n",
    "delStopWordList4 = []\n",
    "\n",
    "for word in NSpaceList4 :\n",
    "    if word in stopWords :\n",
    "        pass\n",
    "    else :\n",
    "        delStopWordList4.append(word)\n",
    "\n",
    "#불용성 영단어 제거 후 단어 빈도수 확인\n",
    "seattle_dic = {}\n",
    "\n",
    "for x in delStopWordList4 :\n",
    "    seattle_dic[x] = delStopWordList4.count(x)\n",
    "    \n",
    "#html소스 저장        \n",
    "f = open('www.seattle.gov.html', 'w')\n",
    "f.write(real_source4)\n",
    "f.close()\n",
    "\n",
    "#단어 빈도수 저장\n",
    "f = open('www.seattle.gov.frequency', 'w')\n",
    "pickle.dump(seattle_dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ neighbors : 1, all : 2, concept : 1, Winter : 1, Fix : 1, focus : 2, Seattles : 1, NonEnglish : 1, debris : 1, deadline : 1, Take : 2, Department : 5, Reiswig : 1, issues : 1, increase : 1, Notice : 3, Business : 3, Watch : 2, languages : 2, program : 1, Western : 1, recycle : 2, Frequently : 1, Nov : 1, must : 1, twoyear : 1, MEETINGS : 1, emergencies : 1, decide : 1, continued : 1, experiencing : 1, joined : 1, 11132015 : 1, Blocking : 1, try : 1, Go : 2, 19952015 : 1, Seattle : 44, enforce : 1, Select : 1, AFFORDABLE : 1, prevent : 1, 8230 : 1, neighborhood : 2, andor : 1, Duwamish : 1, located : 1, street : 2, design : 1, Northwest : 1, INNOVATIVE : 1, 7th : 1, East : 1, index : 1, TTY : 1, Responses : 2, Releases : 2, selected : 1, access : 1, conduct : 1, new : 3, Line : 1, Southwest : 1, Sally : 1, public : 1, seeks : 1, transportation : 1, Neighborhoods : 2, CityLink : 1, Budget : 2, Departments : 3, tracks : 1, Contact : 4, Green : 1, Us : 3, meet : 1, My : 2, box : 2, Piperrsquos : 1, Avenue : 6, Tuesday : 2, Recycling : 2, experience : 1, Your : 1, Legacy : 1, survey : 1, 34025 : 1, action : 1, Home : 3, residents : 1, navigation : 1, Staff : 1, Dexter : 1, campaign : 1, Visiting : 3, Justice : 1, transit : 2, Visit : 3, Conditions : 3, crisis : 2, from : 4, working : 2, steering : 2, bike : 1, Seattlegov : 2, Lane : 2, successful : 1, about : 2, St : 2, Services : 5, visual : 1, midst : 1, hold : 1, blocking : 2, Latest : 2, join : 3, work : 1, Pacific : 1, Video : 1, can : 4, Navigate : 1, growing : 1, ferry : 1, 6848888 : 1, Murrayrsquos : 1, Police : 2, stream : 1, process : 1, Media : 1, JavaScript : 2, DPD : 2, Policy : 1, information : 2, turn : 1, rather : 2, six : 1, how : 2, Downtown : 2, III : 1, LATEST : 1, A : 4, map : 1, sunny : 1, Request : 1, Working : 1, 4th : 1, trees : 1, waterfront : 1, Dow : 1, View : 2, All : 1, Community : 2, Weather : 1, democratic : 1, What : 2, serving : 1, feedback : 1, consent : 1, mission : 1, Popular : 2, QuestionsComplaints : 1, Olezeski : 1, committee : 2, Income : 1, 981047097 : 2, Final : 1, before : 1, group : 2, Greater : 1, 23 : 1, 6844000 : 1, 28 : 1, Here : 1, better : 1, Incident : 2, 2016 : 3, seeking : 1, outlined : 1, safe : 1, dock : 1, Hosts : 1, Social : 1, Delridge : 1, Works : 1, day : 1, preschool : 1, Skip : 1, Minimum : 1, Council : 6, Storm : 1, 701 : 2, FAQs : 1, our : 1, Mayors : 2, More : 2, nbspnbspMayors : 1, decree : 1, Added : 1, 3rd : 1, content : 2, Job : 2, safety : 1, 7 : 1, OrsquoBrien : 1, Jon : 1, Join : 1, G : 1, city : 1, 98104 : 3, University : 1, free : 1, members : 1, Transportation : 2, Security : 1, Options : 1, Tao : 1, Videos : 2, September : 1, Photo : 5, Topics : 1, conversation : 1, musicians : 1, homelessness : 3, app : 1, housing : 1, Copyright : 1, Please : 2, Officers : 1, one : 1, Maps : 1, Performanceseattlegov : 1, Local : 1, 2050 : 2, North : 1, blossom : 1, Post : 1, finances : 1, Pike : 2, B : 2, Language : 1, cops : 1, part : 1, than : 2, SeattleGov : 2, Repair : 2, 13 : 2, 12 : 1, 14 : 1, 17 : 3, 16 : 1, Recommended : 1, final : 1, project : 1, matter : 1, See : 1, video : 1, Councilmembers : 2, declare : 1, browser : 2, enforcement : 2, Pay : 2, partnership : 1, ages : 1, Sites : 1, Submit : 1, Current : 1, Call : 1, have : 1, 2066842489 : 1, Trumba : 1, which : 1, online : 1, Ask : 2, Citys : 1, Hall : 2, sure : 1, 206 : 6, VIBRANT : 1, collaboration : 1, salmon : 2, what : 1, Reports : 1, extending : 1, Inequality : 1, connected : 1, Constantine : 2, services : 2, The : 3, Asked : 1, Vision : 1, CITY : 6, Attorney : 4, mobile : 1, gather : 1, spend : 1, Zonesrsquo : 1, Potholes : 2, Utility : 2, Its : 1, Fifth : 2, 2330025 : 1, Web : 2, Northeast : 1, WA : 7, Union : 4, meetings : 1, supported : 1, Loading : 1, solutions : 1, Suite : 2, Anne : 1, Public : 1, Resources : 3, staff : 1, proposed : 2, crime : 1, LIVE : 1, Traffic : 3, Complaints : 1, announce : 1, local : 2, INTERCONNECTED : 1, achieve : 1, watch : 1, 1319 : 1, Nondiscrimination : 2, nightrsquos : 1, 6848200 : 1, Quick : 1, twomonth : 1, areas : 1, SelfService : 1, Help : 4, settings : 1, Washington : 2, Toggle : 1, 981244025 : 1, through : 2, vision : 2, view : 1, respond : 2, affordable : 2, declared : 1, adopt : 2, national : 1, innovative : 2, Call2066842489CITY : 1, Priority : 1, see : 1, calendar : 1, John : 2, youth : 2, DataSeattleGov : 1, Comprehensive : 2, review : 2, Park : 2, PB : 2, approach : 1, PO : 1, urban : 2, Info : 1, King : 2, we : 3, Central : 1, Budgeting : 2, unsheltered : 1, Team : 1, Directory : 2, 20 : 1, cities : 1, come : 1, improve : 1, AND : 1, last : 1, Give : 1, Through : 1, operating : 1, clogged : 1, Friday : 2, study : 1, Sailboat : 1, community : 3, 2nd : 1, Music : 1, news : 1, throughout : 1, Events : 2, powered : 1, Bus : 1, Floor : 2, Plan : 4, Cherry : 1, pm : 1, website : 2, ndash : 1, enable : 1, lanes : 1, Center : 1, Ballard : 1, N : 1, races : 1, 169 : 1, Learn : 1, Neighborhood : 3, Holmes : 2, main : 1, 6848587 : 1, budget : 3, Okamoto : 1, Follow : 1, Mercer : 2, guide : 1, City : 37, 30 : 1, Engagement : 1, Bagshaw : 1, site : 2, Better : 1, Tim : 1, Gasworks : 1, politics : 1, You : 1, Cramer : 1, make : 3, Address : 5, Design : 1, WeighIn : 1, Map : 4, I : 2, Project : 2, Addressing : 1, programs : 1, Ed : 3, It : 2, Need : 2, investments : 2, latest : 1, Pete : 1, Living : 3, Rapid : 1, Service : 3, 6848566 : 1, Fourth : 2, web : 1, Fax : 1, Privacy : 1, help : 1, realize : 1, News : 2, EVENTS : 1, On : 1, emergency : 1, evaluate : 1, SAFE : 1, MySeattleGov : 2, early : 1, performance : 1, redesign : 1, Gas : 1, Creek : 1, Links : 1, vibrant : 1, individuals : 1, leaves : 1, Find : 6, people : 1, Online : 1, MagnoliaQueen : 1, Application : 1, Between : 1, Employee : 2, New : 1, practical : 1, Channel : 6, Listen : 1, Mike : 1, Lee : 1, comments : 1, Southeast : 1, provides : 1, 911 : 2, Blogs : 1, Box : 2, run : 1, Bill : 2, Daily : 1, Mailing : 2, hearing : 1, Madison : 2, Retiree : 1, most : 1, December : 1, Transit : 2, US : 1, ideology : 1, Questions : 2, Mayor : 10, OpenBudgetseattlegov : 1, within : 1, Draft : 2, finalizing : 1, Corridor : 2, happening : 1, gtgt : 5, your : 4, Enforcement : 2, spending : 1, support : 1, question : 1, Collection : 2, fight : 1, CLOSE : 1, November : 9, We39re : 1, Participatory : 2, drains : 2, hear : 1, goals : 1, ADA : 1, bitesize : 1, posted : 1, County : 2, responding : 1, input : 1, Office : 1, House : 2, BRT : 2, Murray : 9, clips : 1, Ave : 2, urging : 1, Wage : 1, Durkan : 1, 600 : 3, Scheinbeim : 1, universal : 1, Lake : 4, Parks : 1, an : 2, Blog : 1, How : 1, Edward : 2, departments : 1, NEWS : 1, campus : 1, lsquoMusicians : 1, again : 1, amendments : 1, Shorts : 1, interested : 1, 5 : 2, SDOT : 1, you : 2, Customer : 2, AN : 3, South : 3, lane : 1, Updates : 1, Garbage : 2, Executive : 1, together : 1, An : 1, Highlights : 1, Street : 5, time : 1, Open : 2, Conduct : 1, 8th : 1, }\n"
     ]
    }
   ],
   "source": [
    "f = open('www.seattle.gov.frequency')\n",
    "loadtxt = pickle.load(f)\n",
    "print '{',\n",
    "for x in loadtxt :\n",
    "    print \"%s : %d,\" % (x, loadtxt[x]), \n",
    "print '}'\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "punc = string.punctuation\n",
    "\n",
    "source5 = urllib2.urlopen(\"http://www.nationalgeographic.com/\").read()\n",
    "real_source5 = source5\n",
    "\n",
    "for i in range(0, source5.count('<script')) :\n",
    "    if source5.find('<script') != -1 :\n",
    "        source5=source5.replace(source5[source5.find('<script'):source5.find('</script>')+9],\"\")\n",
    "        \n",
    "for i in range(0, source5.count('<style')) :\n",
    "    if source5.find('<style') != -1 :\n",
    "        source5=source5.replace(source5[source5.find('<style'):source5.find('</style>')+8],\"\")\n",
    "\n",
    "for i in range(0, source5.count('<!--')):\n",
    "    if source5.find(\"<!--\") != -1:\n",
    "        source5 = source5.replace(source5[source5.find(\"<!--\"):source5.find(\"-->\")+3:],\"\")\n",
    "        \n",
    "for i in range(0,source5.count(\"<\")):\n",
    "    if source5.find(\"<\") != -1:\n",
    "        source5 = source5.replace(source5[source5.find(\"<\"):source5.find(\">\")+1:],\"\")\n",
    "        \n",
    "words5 = source5.split()\n",
    "\n",
    "delPuncList5 = []\n",
    "puncStr5 = ''\n",
    "\n",
    "# punctuation(구두문자) 제거\n",
    "\n",
    "for x in words5:\n",
    "    puncStr5 = ''\n",
    "    for y in x:\n",
    "        if y in punc :\n",
    "            puncStr5 = puncStr5 + ''\n",
    "        else :\n",
    "            puncStr5 = puncStr5 + y\n",
    "    delPuncList5.append(puncStr5)\n",
    "    \n",
    "# 구두문자 제거 후 출력\n",
    "#for x in delPuncList5 :\n",
    "#    print x\n",
    "\n",
    "NSpaceList5 = []\n",
    "\n",
    "#공백문자 제거\n",
    "for x in delPuncList5 :\n",
    "    if x in string.whitespace :\n",
    "        pass\n",
    "    else :\n",
    "        NSpaceList5.append(x)\n",
    "\n",
    "#공백문자 제거 후 출력        \n",
    "#for x in NSpaceList5 :\n",
    "#    print x\n",
    "    \n",
    "#단어 빈도수 확인\n",
    "ng_dic = {}\n",
    "\n",
    "for x in NSpaceList5 :\n",
    "    ng_dic[x] = NSpaceList5.count(x)\n",
    "    \n",
    "stopWords = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', \n",
    "              'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']\n",
    "\n",
    "delStopWordList5 = []\n",
    "\n",
    "for word in NSpaceList5 :\n",
    "    if word in stopWords :\n",
    "        pass\n",
    "    else :\n",
    "        delStopWordList5.append(word)\n",
    "\n",
    "#불용성 영단어 제거 후 단어 빈도수 확인\n",
    "ng_dic = {}\n",
    "\n",
    "for x in delStopWordList5 :\n",
    "    ng_dic[x] = delStopWordList5.count(x)\n",
    "    \n",
    "#html소스 저장        \n",
    "f = open('www.nationalgeographic.com.html', 'w')\n",
    "f.write(real_source5)\n",
    "f.close()\n",
    "\n",
    "#단어 빈도수 저장\n",
    "f = open('www.nationalgeographic.com.frequency', 'w')\n",
    "pickle.dump(ng_dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ Animals : 1, Nature : 1, National : 1, Images : 1, Cultures : 1, Geographic : 1, }\n"
     ]
    }
   ],
   "source": [
    "f = open('www.nationalgeographic.com.frequency')\n",
    "loadtxt = pickle.load(f)\n",
    "print '{',\n",
    "for x in loadtxt :\n",
    "    print \"%s : %d,\" % (x, loadtxt[x]), \n",
    "print '}'\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) 위 문제에서 저장한 모든 words.frequency 파일들을 객체로 다시 로드하여 본인이 저장하여 분석한 사이트들에서 가장 많이 출현한 단어 3개를 뽑아 제시하시오.\n",
    "반드시 pickle 모듈로 저장한 5개 이상의 words.frequency를 다시 5개 이상의 사전 객체로 로드 하는 코드가 추가되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f0 = open('nytimes.com.frequency')\n",
    "f1 = open('yukoncollege.yk.ca.frequency')\n",
    "f2 = open('www.apple.com.frequency')\n",
    "f3 = open('www.yvr.ca.frequency')\n",
    "f4 = open('www.seattle.gov.frequency')\n",
    "f5 = open('www.nationalgeographic.com.frequency')\n",
    "\n",
    "load_f0 = pickle.load(f0); load_f1 = pickle.load(f1); load_f2 = pickle.load(f2);\n",
    "load_f3 = pickle.load(f3); load_f4 = pickle.load(f4); load_f5 = pickle.load(f5);\n",
    "frqAllWord = {}\n",
    "\n",
    "for word in load_f0:\n",
    "    if word not in frqAllWord :\n",
    "        frqAllWord[word] = 1\n",
    "    else :\n",
    "        frqAllWord[word] += 1\n",
    "        \n",
    "for word in load_f1:\n",
    "    if word not in frqAllWord :\n",
    "        frqAllWord[word] = 1\n",
    "    else :\n",
    "        frqAllWord[word] += 1\n",
    "        \n",
    "for word in load_f2:\n",
    "    if word not in frqAllWord :\n",
    "        frqAllWord[word] = 1\n",
    "    else :\n",
    "        frqAllWord[word] += 1\n",
    "        \n",
    "for word in load_f3:\n",
    "    if word not in frqAllWord :\n",
    "        frqAllWord[word] = 1\n",
    "    else :\n",
    "        frqAllWord[word] += 1\n",
    "\n",
    "for word in load_f4:\n",
    "    if word not in frqAllWord :\n",
    "        frqAllWord[word] = 1\n",
    "    else :\n",
    "        frqAllWord[word] += 1\n",
    "        \n",
    "for word in load_f5:\n",
    "    if word not in frqAllWord :\n",
    "        frqAllWord[word] = 1\n",
    "    else :\n",
    "        frqAllWord[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy 5\n",
      "Contact 5\n",
      "The 5\n"
     ]
    }
   ],
   "source": [
    "show = 1\n",
    "\n",
    "for key, value in sorted(frqAllWord.items(), key=lambda item:item[1], reverse=True) :  # 순서 정렬(값 기준)\n",
    "    print key, value\n",
    "    show += 1\n",
    "    if show == 4 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이트별 불용성 단어를 제외하여 빈도수를 파악하였다.\n",
    "- 각각의 파일들을 읽어 pickle.load()을 이용하였다.\n",
    "- 파일별 단어 빈도수를 종합하는 frqAllWord 사전을 만들어 value를 기준으로 단어들을 정렬한 후 상위 3개의 단어를 출력시켰다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###[소감]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c언어와 비교했을 때 파이썬의 파일 입출력은 쉽게 표현이 되는 것 같다. 단순히 읽는 것 뿐만 아니라 리스트 등으로 바로 저장가능하므로 상황에 맞는 함수를 사용하면 효과적으로 소스를 짤 수 있을 것 같다.\n",
    "- 전체적으로 사용법이 익숙치 않았다. 복습 또한 철저히 하여 이전에 배운 것들과 앞으로 배울 것들에 무리없이 적용할 수 있도록 해야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
